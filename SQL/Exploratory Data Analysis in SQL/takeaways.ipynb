{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coalesce : ` SELECT COALESCE(column_1, column_2) FROM table_name`\n",
    "- Casting : `SELECT CAST (3.7 AS integer);`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Variance\n",
    "SELECT variance(col_name) FROM table_name;\n",
    "-- Population variace \n",
    "SELECT var_pop(col_name) FROM table_name;\n",
    "-- Sample variace \n",
    "SELECT var_samp(col_name) FROM table_name;\n",
    "-- Standard deviation \n",
    "SELECT stddev(col_name) FROM table_name;\n",
    "\n",
    "-- population standard deviation \n",
    "SELECT stddev_pop(col_name) FROM table_name;\n",
    "-- sample standard deviation \n",
    "SELECT stddev_samp(col_name) FROM table_name;\n",
    "-- truncate \n",
    "SELECT trunc(42.1256, 2); -- (42.12)\n",
    "-- series \n",
    "SELECT generate_series(1, 10, 2); -- (1,3 ... , 9)\n",
    "-- correlation \n",
    "SELECT corr(assets, equity) FROM fortune500;\n",
    "-- continuous percentile \n",
    "SELECT percentile_cont(0.5) WITHIN GROUP (ORDER BY col_name) FROM table_name;\n",
    "-- discrete percentile \n",
    "SELECT percentile_disc(0.5) WITHIN GROUP (ORDER BY col_name) FROM table_name;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Create bins\n",
    "WITH bins AS\n",
    "    ( SELECT generate_series(30 , 60 , 5) AS lower, \n",
    "    generate_series(35 , 65, 5) AS upper),\n",
    "-- Subset data to tag of interest\n",
    "ebs AS \n",
    "    ( SELECT unanswered_count FROM stackoverflow \n",
    "    WHERE tag = 'amazon-ebs')\n",
    "-- Count values in each bin\n",
    "SELECT lower, upper, count(unanswered_count)\n",
    "-- left join keeps all bins\n",
    "FROM bins\n",
    "LEFT JOIN ebs\n",
    "ON unanswered_count >= lower AND unanswered_count < upper \n",
    "-- Group by bin bounds to create the groups\n",
    "GROUP BY lower, upper\n",
    "ORDER BY lower;\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Bins from Step 1\n",
    "WITH bins AS (\n",
    "\t SELECT generate_series('2016-01-01',\n",
    "                            '2018-01-01',\n",
    "                            '6 months'::interval) AS lower,\n",
    "            generate_series('2016-07-01',\n",
    "                            '2018-07-01',\n",
    "                            '6 months'::interval) AS upper),\n",
    "-- Daily counts from Step 2\n",
    "     daily_counts AS (\n",
    "     SELECT day, count(date_created) AS count\n",
    "       FROM (SELECT generate_series('2016-01-01',\n",
    "                                    '2018-06-30',\n",
    "                                    '1 day'::interval)::date AS day) AS daily_series\n",
    "            LEFT JOIN evanston311\n",
    "            ON day = date_created::date\n",
    "      GROUP BY day)\n",
    "-- Select bin bounds \n",
    "SELECT lower, \n",
    "       upper, \n",
    "       -- Compute median of count for each bin\n",
    "       percentile_disc(0.5) WITHIN GROUP (ORDER BY count) AS median\n",
    "  -- Join bins and daily_counts\n",
    "  FROM bins\n",
    "       LEFT JOIN daily_counts\n",
    "       -- Where the day is between the bin bounds\n",
    "       ON day >= lower\n",
    "          AND day < upper\n",
    " -- Group by bin bounds\n",
    " GROUP BY lower, upper\n",
    " ORDER BY lower;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Create temp table\n",
    "CREATE TEMP TABLE temp_table (\n",
    "    id INT,\n",
    "    name VARCHAR(30)\n",
    ");\n",
    "\n",
    "-- Query results to store in the temporary table on the fly\n",
    "CREATE TEMP TABLE temp_table AS\n",
    "SELECT column1, column2\n",
    "FROM table_name;\n",
    "\n",
    "-- Insert values in temporary table from another table\n",
    "INSERT INTO temp_table\n",
    "SELECT column1, column2\n",
    "FROM another_table\n",
    "\n",
    "-- Delete temporary table\n",
    "DROP TABLE IF EXISTS temp_table;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lowercase : `SELECT lower('ABC');` (abc)\n",
    "- uppercase : `SELECT lower('abc');` (ABC)\n",
    "- pattern matching case sensitive : `SELECT * FROM table_name  WHERE col_name LIKE '%apple%';`\n",
    "- pattern matching case insensitive : `SELECT * FROM table_name  WHERE col_name ILIKE '%apple%';`\n",
    "- trimming : `SELECT trim('Wow!', '!wW');` (o). Also `rtrim`, `ltrim`\n",
    "- substring : `SELECT substr('abcdef', 2, 3);` (bcd)\n",
    "- splitting: `SELECT split_part('a,bc,d', ',', 2);` (bc)\n",
    "- Concatenating : `SELECT concat('a', 2, 'cc');` (a2cc) ALSO `concat_ws()`\n",
    "- Concatenating : `SSELECT 'a' || 2 || 'cc';` (a2cc) (NOTE: Any NULL will produce NULL result )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Assume you have the CTE\n",
    "WITH cte AS (\n",
    "    SELECT STRING_AGG(Country, ', ') AS ConcatenatedCountries\n",
    "    FROM Country_Medals\n",
    ")\n",
    "SELECT value AS Country\n",
    "FROM cte\n",
    "CROSS APPLY STRING_SPLIT(cte.ConcatenatedCountries, ', '); -- Use STRING_SPLIT with CROSS APPLY\n",
    "\n",
    "-- Split into words\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN category LIKE '%: %' THEN SPLIT_PART(category, ': ', 1)\n",
    "        WHEN category LIKE '% - %' THEN SPLIT_PART(category, ' - ', 1)\n",
    "        ELSE SPLIT_PART(category, ' | ', 1)\n",
    "        END AS major_category, -- alias the result\n",
    "sum(businesses) -- also select number of businesses\n",
    "FROM naics\n",
    "GROUP BY major_category;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL column operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Change column type\n",
    "ALTER TABLE table_name\n",
    "ALTER COLUMN some_col VARCHAR(250);\n",
    "\n",
    "-- Change column name\n",
    "ALTER TABLE table_name\n",
    "RENAME COLUMN old_column_name TO new_column_name;\n",
    "\n",
    "-- Change column values\n",
    "UPDATE table_name\n",
    "SET col_name=LOWER(col_name);\n",
    "\n",
    "-- Add column\n",
    "ALTER TABLE table_name\n",
    "ADD COLUMN new_col INTEGER;\n",
    "\n",
    "-- DELETE column\n",
    "ALTER TABLE table_name\n",
    "DROP COLUMN col_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- DATE operations (Advised : Use TIMESTAMP FORMAT instead of DATE FORMAT to acquire preciseness)\n",
    "SELECT date '2005-09-11' - date '2005-09-10'; -- Result will be an integer as no of days (1)\n",
    "SELECT date '2005-09-11' + integer '3'; -- Result will be a date (2005-09-14)\n",
    "SELECT '2018-12-10'::DATE + '1 year 2 days 3 minutes'::INTERVAL ; -- Result will be a date\n",
    "\n",
    "-- TIMESTAMP operations\n",
    "SELECT date '2005-09-11 00:00:00' - date '2005-09-09 12:00:00'; -- Result will be an interval (1 day 12:00:00)\n",
    "SELECT AGE(timestamp '2005-09-11 00:00:00', timestamp '2005-09-09 12:00:00'); -- Result will be an interval (1 day 12:00:00)\n",
    "SELECT timestamp '2019-05-01' + 21 * INTERVAL '1 day';  -- Result will be a new timestamp (2019-05-22 00:00:00)\n",
    "SELECT rental_date + INTERVAL '3 days' AS expected_return_date -- adding timestamp with interval = new timestamp\n",
    "FROM rental;\n",
    "\n",
    "-- Current Timestamp\n",
    "SELECT NOW()::timestamp;    -- casting will cut the timezone information\n",
    "SELECT CAST(NOW() as timestamp);\n",
    "SELECT CURRENT_TIMESTAMP(2); -- control precision\n",
    "SELECT CURRENT_DATE; -- current date\n",
    "SELECT CURRENT_TIME; -- current time with timezone information\n",
    "\n",
    "-- Extract date and time information\n",
    "SELECT EXTRACT (month FROM timestamp '2005-01-24 05:12:00') AS month; -- Result will be month (1)\n",
    "SELECT DATE_PART('month', timestamp '2005-01-24 05:12:00') AS month; -- Result will be month (1)\n",
    "SELECT DATE_TRUNC('year', TIMESTAMP '2005-05-21 15:30:30'); -- Result will truncate to specified precision (2005-01-01 00:00:00)\n",
    "\n",
    "-- Time Series generation\n",
    "SELECT GENERATE_SERIES('2018-01-01', '2019-01-01', '1 month'::INTERVAL) - '1 day'::INTERVAL;\n",
    "\n",
    "-- Lead and lag operations (go back or go forward in time)\n",
    "SELECT date_col, lead(date_col) OVER (ORDER BY date_col) FROM table_name;\n",
    "SELECT date_col, lag(date_col) OVER (ORDER BY date_col) FROM table_name;\n",
    "\n",
    "-- String formatting of date\n",
    "SELECT TO_CHAR(my_date_column, 'Month DD, YYYY') AS custom_date_format FROM my_table;\n",
    "-- Reverse this process\n",
    "SELECT TO_DATE('February 14, 2024', 'Month DD, YYYY') AS original_date FROM converted_table;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- String formatting of date\n",
    "SELECT TO_CHAR(my_date_column, 'Month DD, YYYY') AS custom_date_format FROM my_table;\n",
    "-- Reverse this process\n",
    "SELECT TO_DATE('February 14, 2024', 'Month DD, YYYY') AS original_date FROM converted_table;\n",
    "-- custom number formatting\n",
    "SELECT TO_CHAR(my_numeric_column, '$999,999.99') AS formatted_number FROM my_table;\n",
    "-- Reverse this process\n",
    "SELECT TO_NUMBER(REPLACE(formatted_number, '$', ''), '999999.99') AS original_numeric_value FROM converted_table;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
