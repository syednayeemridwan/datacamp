{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spark session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "\t.master('local[*]') \\ # Location of cluster, use all cores of local computer\n",
    "    .appName(\"Load and Query CSV with SQL\") \\\n",
    "    .getOrCreate()\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "StructField(\"col1\", StringType()),\n",
    "StructField(\"col2\", IntegerType()),\n",
    "StructField(\"col3\", DoubleType())\n",
    "])\n",
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.csv(\"file.csv\",sep=',', header=True, inferSchema=True, nullValue='NA') # schema= schema\n",
    "# Check column types\n",
    "df.printSchema()\n",
    "df.dtypes\n",
    "# Register the DataFrame as a temporary table or view\n",
    "df.createOrReplaceTempView(\"my_table\")\n",
    "# Print the tables in the catalog\n",
    "print(spark.catalog.listTables())\n",
    "# Run SQL queries on the DataFrame\n",
    "query_result = spark.sql(\"SELECT * FROM my_table WHERE column_name = 'value'\")\n",
    "query_result.show()\n",
    "\n",
    "sc = spark.sparkContext # Access the SparkContext from SparkSession\n",
    "spark = SparkSession(sc) # Create a SparkSession from SparkContext\n",
    "spark.stop() # Stop SparkSession\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
