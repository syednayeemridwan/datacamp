{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlation = root of r-squared\n",
    "- Correlation between time series:\n",
    "    - if 2 different stocks are trending, their correlation is high even if they do not show same pattern\n",
    "    - Correct way : find correlation between the stock returns instead (eg: correlation between daily percentage change of two stocks)\n",
    "- Predicting future points using regression : dependent time series = independent time series * slope + intercept + error\n",
    "- Auto-correlation:\n",
    "    - correlation between a time series with a lagged version of itself\n",
    "    - an \"echo\" that exists in all points in a time series with other points in the past\n",
    "    - eg: 1,2,3,4,5,6,7 in this series second number = first number + 1, third number = second number + 1.. this exist for all points\n",
    "    - Negative autocorrelation = mean reverting\n",
    "        - stocks have historically negative autocorrelation over weeks\n",
    "        - strategy to make money : buy down -> sell up\n",
    "    - Positive autocorrrelation = momentum\n",
    "        - commodities and currencies have historically positive autocorrelation over months\n",
    "        - strategy to make money : buy up -> sell down\n",
    "    - An autocorrelation graph \n",
    "        - shows how many past points (lags) can we use to predict the future (including the present point).\n",
    "        - Shows suitable model for prediction\n",
    "- White Noise\n",
    "    - constant mean over time\n",
    "    - constant variance over time\n",
    "    - 0 autocorrelation at all lags\n",
    "    - Gaussian White Noise : the white noise has gaussian distribution and show bell curve\n",
    "- Random Walk and White noise\n",
    "    - Stock market follow a random walk, and so the return (gain or percent change) is white noise (Yesterday price - Today price = noise)\n",
    "    - You cannot forecast a random walk. The best guess : todays price is same as yesterdays price\n",
    "    - random walk with drift = random walk + mean (drift)\n",
    "    - So, although we cannot forecast a random walk, we can guess the direction of the walk with the value of drift\n",
    "    - How do we make sure if a series is rendom walk?\n",
    "        - Dickey Fuller Test : You can test if a series is random walk\n",
    "        - Augmented Dickey Fuller Test : Test if a series is random walk with more than one lags through augmentation\n",
    "- Stationarity\n",
    "    - Strong stationarity : Entire distribution of data is time invariant\n",
    "    - Weak stationarity : mean, variance and autocorrelation of data are time invariant\n",
    "    - stationary data is easy to model due to less number of parameters\n",
    "    - non-stationary data is hard to model due to large number of parameters (new parameters found for each point in time)\n",
    "    - eg: stock price is non-stationary. reason : price of today will differ from price of 10 years into the future\n",
    "    - eg: white noise is stationary. reason : mean, variance and auto-correlation of 100 data is same as 1000 data points\n",
    "    - non-stationary to stationary : may require several transformations like:\n",
    "        1. log transformation\n",
    "        2. take the difference between current and a lagged version of itself (the right lag = look at acf graph)\n",
    "    - Regression model:\n",
    "        1. AR model : \n",
    "            - Theory : The next value should retain some information from the previous value\n",
    "            - todays value = mean + co-efficient * yesterday's value + error (y = mx + c)\n",
    "            - co-efficient = phi. Negative phi = mean reversion, positive phi = momentum\n",
    "            - phi = 0 for random walk (high autocorrelation) , phi = 1 for white noise (no autocorrelation) , -1 < phi < +1 for stationary series\n",
    "            - autocorrelation decays exponentially at a rate of phi\n",
    "        1. MA model : todays value = mean + co-efficient * yesterday's value + error\n",
    "            - todays value = mean + co-efficient * yesterday's value + error (y = mx + c)\n",
    "- Partial auto-correlation : \n",
    "    - incremental benefit of adding another lag\n",
    "    - quantifies how significance adding n-th lag is when there is already (n-1)th lag\n",
    "- Information Criteria : adjusts penalties on number of parameters in the model. The best model has least AIC or/and BIC model among the peers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "df['num_col'].autocorr() # autocorrelation value\n",
    "# Plot ACF and PACF graph\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(df['num_col'], lags= 20, alpha=0.05) # alpha = 1 - confidence interval\n",
    "plot_pacf(df['num_col'], lags= 20, alpha=0.05)\n",
    "from statsmodels.tsa.stattools import acf\n",
    "acf(df['num_col']) # See acf values\n",
    "# White noise\n",
    "import numpy as np\n",
    "noise = np.random.normal(loc=0, scale=1, size=500)\n",
    "# Dickey Fuller test for random walk\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adfuller(df['num_col'])\n",
    "# Pure AR Series generation\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "phi = 0.9\n",
    "ar = np.array([1, -phi])\n",
    "ma = np.array([1])\n",
    "AR_object = ArmaProcess(ar, ma)\n",
    "simulated_data = AR_object.generate_sample(nsample=1000)\n",
    "plt.plot(simulated_data)\n",
    "# ARIMA modeling \n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "model = ARIMA(data, order=(1,0,0)) # (AR, diff, MA)\n",
    "result = model.fit()\n",
    "forecast = result.get_forecast(steps=50) # Forecast next 50 values\n",
    "print(result.summary())\n",
    "print(result.params) # Returns constant meu, and co-efficient phi\n",
    "print(result.aic, result.bic) # AIC and BIC values of the model\n",
    "# Plotting forecast\n",
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "fig, ax = plt.subplots()\n",
    "data.plot(ax=ax)\n",
    "plot_predict(result, start='2012-09-27', end='2012-10-06', alpha=0.05, ax=ax)\n",
    "plt.show()\n",
    "# Visualize best model : AR or MA values on X axis and AIC, BIC on Y axis\n",
    "plt.plot(ar_values, aic_values, label='AIC', marker='o')\n",
    "plt.plot(ar_values, bic_values, label='BIC', marker='o')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between values vs Correlation between percent changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"images/01.01.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive and Negative Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01.02.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/01.03.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.01.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.02.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Noise : A perfect example of stationary time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.03.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk and Dicky-Fuller Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.04.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.05.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-stationary time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.06.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.07.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.08.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation : non-stationary to stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.09.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.10.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.11.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR series with different phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/03.01.png\"  style=\"width: 400px, height: 300px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of phi on Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/03.02.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR model with multiple lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/03.03.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PACF of AR with different lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/03.04.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
