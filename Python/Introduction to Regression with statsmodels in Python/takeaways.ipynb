{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Response variable = dependent variable = y\n",
    "- Explanatory variables = independent variables = X\n",
    "- Linear regression = The response variable is numeric\n",
    "- Logistic regression = The response variable is logical.\n",
    "- Simple linear/logistic regression = There is only one explanatory variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# You want a regression line : y = mx + c\n",
    "from statsmodels.formula.api import ols\n",
    "# Formula applied : y = x, finds m and c on its own for best fit\n",
    "num_model = ols(\"y ~ x_num\", data=df).fit()\n",
    "# Calculate co-efficient of each category with relative to 0 instead of relative to intercept, its the mean for each category\n",
    "cat_model = ols(\"y ~ x_cat + 0\", data=df).fit()\n",
    "# See model params : slope m and intercept c\n",
    "print(cat_model.params)\n",
    "# See prediction on original fitted data \n",
    "print(num_model.fittedvalues)\n",
    "# See residuals\n",
    "print(model.resid)\n",
    "# Model summary\n",
    "model.summary()\n",
    "# R-squared\n",
    "print(model.rsquared)\n",
    "# Residual mean squared error\n",
    "rse = np.sqrt(model.mse_resid)\n",
    "# Create test data\n",
    "test_data = pd.DataFrame({\"x_num\": np.arange(20, 41)})\n",
    "# Predict on test data\n",
    "print(num_model.predict(test_data))\n",
    "# Summary values\n",
    "summary_df = model.get_influence().summary_frame()\n",
    "# Leverage\n",
    "df[\"leverage\"] = summary_df[\"hat_diag\"]\n",
    "# Cooks distance\n",
    "summary_df[\"cooks_dist\"] = summary_df[\"cooks_d\"]\n",
    "# Residual plot\n",
    "sns.residplot(x=\"X\", y=\"y\", data=bream, lowess=True)\n",
    "# QQ plot\n",
    "from statsmodels.api import qqplot\n",
    "qqplot(data=model.resid, fit=True, line=\"45\")\n",
    "# Scale location plot\n",
    "residual_abs_squared = model.get_influence().resid_studentized_internal\n",
    "residual_measured = np.sqrt(residual_abs_squared)\n",
    "sns.regplot(x=model.fittedvalues, y=residual_measured, ci=None, lowess=True)\n",
    "# NOTE : You can transform the X and y before fitting and then train. You can predict with the model and the predicted values should be back-transformed for y if y was transformed.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Response value = fitted value + residuals\n",
    "- Regression to the mean : extreme cases don't persist over time, they occur due to randomness \n",
    "- Non-linear data may work well with transformation\n",
    "- You may have to transform X, y or both before training or fitting. You need to reverse the transformation result after prediction to interpret the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification:\n",
    "    - Accuracy is not a good metric for all cases. eg: class imbalanced dataset\n",
    "    - accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
    "    - precision = TP / (TP + FP)\n",
    "    - High precision = lower false positive rate\n",
    "    - recall = TP / (TP + FN)\n",
    "    - High recall = lower false negative rate\n",
    "    - f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    - ROC AUC = area under the curve of TP rate vs FP rate graph\n",
    "    - jaccard score\n",
    "    - log loss\n",
    "- Regression:\n",
    "    - r-squared : Percentage of variability of y explained by independent variable\n",
    "    - RMSE : Root mean squared error. Average error in target\n",
    "    - RSE : Residual standard error. Same as RMSE, except instead of length (n), it requires degree of freedom (n-1)\n",
    "    - MAE : Average absolute error in target\n",
    "    - VResidual vs fit plot : Fitted values on X axis vs Residual on Y axis. Good model has positive and negative values distributed evenly on both side of a line (gaussian noise).\n",
    "    - Q-Q Plot : normal distribution on X axis vs dataset distribution on Y axis. Good model has linear relationship of equation line Y= mX + c\n",
    "    - Distance location plot : Fitted values on X-axis vs root of standardized residuals on Y-axis. \n",
    "    - measurement of extreme values (outliers):\n",
    "        - leverage : measurement of how extreme the explanatory variable values are\n",
    "        - influence : how much the model would change if you leave the observation out of the dataset when modeling. (eg : cooks distance)\n",
    "- Hyperparameter tuning = \n",
    "    - Hyperparameters are Parameters we specify before fitting the model\n",
    "    - We compare model outcomes by changing these hyperparametes \n",
    "    - Use cross-validation to avoid overfitting\n",
    "    - example : gridsearch\n",
    "- Use boxplot of cross-validation results of different models to compare their distribution of scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Regression Performance Measurement\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "r2_score(y_true, y_pred) # R-squared\n",
    "mse = mean_squared_error(y_true, y_pred) # MSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False) # RMSE\n",
    "mae = mean_absolute_error(y_true, y_pred) # MAE\n",
    "\n",
    "# Classification Performance Measurement\n",
    "from sklearn.metrics import classification_report, confusion_matrix, jaccard_score, log_loss, roc_auc_score, roc_curve, f1_score\n",
    "confusion_matrix(y_test, y_pred) # Confusion matrix\n",
    "classification_report(y_test, y_pred) # TP, FP, TN, FN\n",
    "jaccard_score(y_test, y_pred,pos_label=0) # Jaccard score\n",
    "log_loss(y_test, y_pred_prob) # log loss\n",
    "print(roc_auc_score(y_test, y_pred_prob)) # ROC AUC\n",
    "print(f1_score(y_true, y_pred)) # F1 Score\n",
    "\n",
    "# Visualize ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Grid-search example for hyperparameter tuning of classification\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {\"alpha\": np.arange(0.0001, 1, 10), \"solver\": [\"sag\", \"lsqr\"]}\n",
    "ridge = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=kf)\n",
    "ridge_cv2 = RandomizedSearchCV(ridge, param_grid, cv=kf, n_iter=2)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "print(ridge_cv.best_params_, ridge_cv.best_score_)\n",
    "\n",
    "### Compare different models distribution\n",
    "results = {\"Model 1\": model1_cv_results, \"Model 2\": model2_cv_results, \"Model 3\": model3_cv_results}\n",
    "plt.boxplot(results.values(), labels=results.keys())\n",
    "plt.show()\n",
    "\n",
    "# Leverage : measurement of how extreme the explanatory variable values are\n",
    "leverage = model.get_influence().hat_matrix_diag\n",
    "# Influence : how much the model would change if you leave the observation out of the dataset when modeling. (eg : cooks distance)\n",
    "influence = model.get_influence().resid_studentized_external\n",
    "cooks_distance = model.get_influence().cooks_distance[0]\n",
    "\n",
    "# Residualplot for regression\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals, color='blue', alpha=0.6)\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Fitted Values (Predicted)')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "# Q-Q plot for regression\n",
    "from scipy.stats import probplot\n",
    "probplot(residuals.flatten(), dist='norm', plot=plt)\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Sample Quantiles')\n",
    "plt.show()\n",
    "\n",
    "# Scale location plot\n",
    "plt.scatter(y_pred, np.sqrt(np.abs(residuals)), color='blue', alpha=0.6)\n",
    "plt.xlabel('Fitted Values (Predicted)')\n",
    "plt.ylabel('Square Root of Absolute Residuals')\n",
    "plt.axhline(y=np.mean(np.sqrt(np.abs(residuals))), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from statsmodels.formula.api import logit\n",
    "model = logit(\"target ~ x_var\", data=df).fit()\n",
    "print(model.params)\n",
    "# Visualize logistic model\n",
    "sns.regplot(x=\"x_var\", y=\"target\", data=df, ci=None, logistic=True)\n",
    "X_test = pd.DataFrame({\"x_var\": np.arange(-1, 6.25, 0.25)})\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.round(y_pred_prob)\n",
    "# Odds ratio : p/(1-p) or probability of something happenning over not happening\n",
    "odds_ratio = y_pred_prob / (1- y_pred_prob)\n",
    "# Visualize odds ratio / log odds ratio : How likely or unlikely an occurrence may happen\n",
    "sns.lineplot(x=\"x_var\", y=\"odds_ratio\", data=df)\n",
    "plt.axhline(y=1, linestyle=\"dotted\")\n",
    "plt.yscale(\"log\") # If you want to make the curve into linear make y : np.log(odds_ratio)\n",
    "plt.show()\n",
    "# Confusion matrix\n",
    "conf_matrix = model.pred_table()\n",
    "TN = conf_matrix[0,0]\n",
    "TP = conf_matrix[1,1]\n",
    "FN = conf_matrix[1,0]\n",
    "FP = conf_matrix[0,1]\n",
    "# Visualize confusion matrix\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "mosaic(conf_matrix)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
