{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've been given a dataset comprised of volunteer information from New York City, stored in the `volunteer` DataFrame. Explore the dataset using the plethora of methods and attributes pandas has to offer to answer the following question.\n",
    "\n",
    "How many missing values are in the `locality` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['opportunity_id', 'content_id', 'vol_requests', 'event_time', 'title',\n",
       "       'hits', 'summary', 'is_priority', 'category_id', 'category_desc',\n",
       "       'amsl', 'amsl_unit', 'org_title', 'org_content_id', 'addresses_count',\n",
       "       'locality', 'region', 'postalcode', 'primary_loc', 'display_url',\n",
       "       'recurrence_type', 'hours', 'created_date', 'last_modified_date',\n",
       "       'start_date_date', 'end_date_date', 'status', 'Latitude', 'Longitude',\n",
       "       'Community Board', 'Community Council ', 'Census Tract', 'BIN', 'BBL',\n",
       "       'NTA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "volunteer = pd.read_csv(\"dataset/volunteer_opportunities.csv\")\n",
    "# volunteer.head()\n",
    "volunteer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer['locality'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've explored the `volunteer` dataset and understand its structure and contents, it's time to begin dropping missing values.\n",
    "\n",
    "In this exercise, you'll drop both columns and rows to create a subset of the `volunteer` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 33)\n"
     ]
    }
   ],
   "source": [
    "# Drop the Latitude and Longitude columns from volunteer\n",
    "volunteer_cols = volunteer.drop(['Latitude' , 'Longitude'], axis=1)\n",
    "\n",
    "# Drop rows with missing category_desc values from volunteer_cols\n",
    "volunteer_subset = volunteer_cols.dropna(subset=['category_desc'])\n",
    "\n",
    "# Print out the shape of the subset\n",
    "print(volunteer_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking another look at the dataset comprised of volunteer information from New York City, you want to know what types you'll be working with as you start to do more preprocessing.\n",
    "\n",
    "Which data types are present in the `volunteer` dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'), dtype('float64'), dtype('O')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(volunteer.dtypes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting a column type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at the `volunteer` dataset types, you'll see that the column `hits` is type `object`. But, if you actually look at the column, you'll see that it consists of integers. Let's convert that column to type `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "opportunity_id          int64\n",
      "content_id              int64\n",
      "vol_requests            int64\n",
      "event_time              int64\n",
      "title                  object\n",
      "hits                    int32\n",
      "summary                object\n",
      "is_priority            object\n",
      "category_id           float64\n",
      "category_desc          object\n",
      "amsl                  float64\n",
      "amsl_unit             float64\n",
      "org_title              object\n",
      "org_content_id          int64\n",
      "addresses_count         int64\n",
      "locality               object\n",
      "region                 object\n",
      "postalcode            float64\n",
      "primary_loc           float64\n",
      "display_url            object\n",
      "recurrence_type        object\n",
      "hours                   int64\n",
      "created_date           object\n",
      "last_modified_date     object\n",
      "start_date_date        object\n",
      "end_date_date          object\n",
      "status                 object\n",
      "Latitude              float64\n",
      "Longitude             float64\n",
      "Community Board       float64\n",
      "Community Council     float64\n",
      "Census Tract          float64\n",
      "BIN                   float64\n",
      "BBL                   float64\n",
      "NTA                   float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the head of the hits column\n",
    "print(volunteer[\"hits\"].dtype)\n",
    "\n",
    "# Convert the hits column to type int\n",
    "volunteer[\"hits\"] = volunteer[\"hits\"].astype(\"int\")\n",
    "\n",
    "# Look at the dtypes of the dataset\n",
    "print(volunteer.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `volunteer` dataset, you're thinking about trying to predict the `category_desc` variable using the other features in the dataset. First, though, you need to know what the class distribution (and imbalance) is for that label.\n",
    "\n",
    "Which descriptions occur less than 50 times in the volunteer dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strengthening Communities    307\n",
       "Helping Neighbors in Need    119\n",
       "Education                     92\n",
       "Health                        52\n",
       "Environment                   32\n",
       "Emergency Preparedness        15\n",
       "Name: category_desc, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer['category_desc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know that the distribution of class labels in the `category_desc` column of the volunteer dataset is uneven. If you wanted to train a model to predict `category_desc`, you'll need to ensure that the model is trained on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strengthening Communities    230\n",
      "Helping Neighbors in Need     89\n",
      "Education                     69\n",
      "Health                        39\n",
      "Environment                   24\n",
      "Emergency Preparedness        11\n",
      "Name: category_desc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create a DataFrame with all columns except category_desc\n",
    "X = volunteer_subset.drop('category_desc', axis=1)\n",
    "\n",
    "# Create a category_desc labels dataset\n",
    "y = volunteer_subset['category_desc']\n",
    "\n",
    "# Use stratified sampling to split up the dataset according to the y dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Print the category_desc counts from y_train\n",
    "print(y_train.value_counts())\n",
    "# y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
