{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hich of the following is a true statement about support vectors? To help you out, here's the picture of support vectors from the video (top), as well as the hinge loss from Chapter 2 (bottom)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/04.03.png\"  style=\"width: 400px, height: 300px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All incorrectly classified points are support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of removing examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vectors are defined as training examples that influence the decision boundary. In this exercise, you'll observe this behavior by removing non support vectors from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a linear SVM\n",
    "# svm = SVC(kernel=\"linear\")\n",
    "# svm.fit(X,y)\n",
    "# plot_classifier(X, y, svm, lims=(11,15,0,6))\n",
    "\n",
    "# # Make a new data set keeping only the support vectors\n",
    "# print(\"Number of original examples\", len(X))\n",
    "# print(\"Number of support vectors\", len(svm.support_))\n",
    "# X_small = X[svm.support_]\n",
    "# y_small = y[svm.support_]\n",
    "\n",
    "# # Train a new SVM using only the support vectors\n",
    "# svm_small = SVC(kernel=\"linear\")\n",
    "# svm_small.fit(X,y)\n",
    "# plot_classifier(X_small, y_small, svm_small, lims=(11,15,0,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV warm-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we saw that increasing the RBF kernel hyperparameter `gamma` increases training accuracy. In this exercise we'll search for the `gamma` that maximizes cross-validation accuracy using scikit-learn's `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate an RBF SVM\n",
    "# svm = SVC()\n",
    "\n",
    "# # Instantiate the GridSearchCV object and run the search\n",
    "# parameters = {'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
    "# searcher = GridSearchCV(svm, parameters)\n",
    "# searcher.fit(X, y)\n",
    "\n",
    "# # Report the best parameters\n",
    "# print(\"Best CV params\", searcher.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointly tuning gamma and C with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value of `gamma` was 0.001 using the default value of `C`, which is 1. In this exercise you'll search for the best combination of `C` and `gamma` using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate an RBF SVM\n",
    "# svm = SVC()\n",
    "\n",
    "# # Instantiate the GridSearchCV object and run the search\n",
    "# parameters = {'C':[0.1, 1, 10], 'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
    "# searcher = GridSearchCV(svm, parameters)\n",
    "# searcher.fit(X_train, y_train)\n",
    "\n",
    "# # Report the best parameters and the corresponding score\n",
    "# print(\"Best CV params\", searcher.best_params_)\n",
    "# print(\"Best CV accuracy\", searcher.best_score_)\n",
    "\n",
    "# # Report the test accuracy using these best parameters\n",
    "# print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An advantage of SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following is an advantage of SVMs over logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- They are computationally efficient with kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An advantage of logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following is an advantage of logistic regression over SVMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It naturally outputs meaningful probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final coding exercise, you'll do a hyperparameter search over the regularization strength and the loss (logistic regression vs. linear SVM) using `SGDClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We set random_state=0 for reproducibility \n",
    "# linear_classifier = SGDClassifier(random_state=0)\n",
    "\n",
    "# # Instantiate the GridSearchCV object and run the search\n",
    "# parameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "#              'loss':['hinge', 'log_loss']}\n",
    "# searcher = GridSearchCV(linear_classifier, parameters, cv=10)\n",
    "# searcher.fit(X_train, y_train)\n",
    "\n",
    "# # Report the best parameters and the corresponding score\n",
    "# print(\"Best CV params\", searcher.best_params_)\n",
    "# print(\"Best CV accuracy\", searcher.best_score_)\n",
    "# print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
