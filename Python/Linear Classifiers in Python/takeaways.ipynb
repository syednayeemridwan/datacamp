{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# First convert dataset to numpy since sklearn uses numpy\n",
    "y = df['target'].values\n",
    "X = df.drop('target', axis=1).values\n",
    "# Normalize the whole dataset before modeling\n",
    "X = preprocessing\\\n",
    "\t.StandardScaler()\\\n",
    "\t.fit(X)\\\n",
    "\t.transform(X.astype(float))\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "# Initialize and train model\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='minkowski')\n",
    "knn.fit(X_train, y_train)\n",
    "# Predict the test set class with the trained model\n",
    "predicted_y = knn.predict(X_test)\n",
    "# Measure probability score of prediction for the test set with the trained model\n",
    "predicted_y_prob = knn.predict_proba(X_test)\n",
    "# Measure accuracy on testing set\n",
    "print(accuracy_score(y_test, predicted_y)*100)\n",
    "# Visualize normal distribution of accuracy for different Ks\n",
    "# Compute the above steps for different K and find mean, std etc\n",
    "plt.plot(range(1,Ks),mean_acc,'g')\n",
    "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.fill_between(range(1,Ks),mean_acc - 3 * std_acc,mean_acc + 3 * std_acc, alpha=0.10,color=\"green\")\n",
    "plt.legend(('Accuracy ', '+/- 1xstd','+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Plot complexity graph with list of train and test accuracies\n",
    "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
    "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Specify independent and dependent features\n",
    "X = np.asarray(df[['A', 'B', 'C', 'D', 'E', 'F', 'G']])\n",
    "y = np.asarray(df['target'])\n",
    "\n",
    "# Preprocess dataset\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# Split into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# Train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear')\n",
    "LR.fit(X_train,y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "# See classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "classification_report(y_test, y_pred)\n",
    "confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "\n",
    "# Predicted probability on test set for positive/target class\n",
    "y_pred_prob = LR.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, y_pred,pos_label=0)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_pred_prob)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_prob))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Method 1\n",
    "from sklearn.svm import LinearSVC\n",
    "# OR from sklearn.svm import SVC \n",
    "# instatiate a scikit-learn SVM model\n",
    "# to indicate the class imbalance at fit time, set class_weight='balanced'\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "svm = LinearSVC(class_weight='balanced', random_state=42, loss=\"hinge\", fit_intercept=False) \n",
    "# svm = SVC(kernel='linear', gamma=.5, probability=True)  # Another way\n",
    "# train a linear Support Vector Machine model using Scikit-Learn\n",
    "t0 = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "sklearn_time = time.time() - t0\n",
    "\n",
    "# Method 2 : Use snapml library\n",
    "# in contrast to scikit-learn's LinearSVC, Snap ML offers multi-threaded CPU/GPU training of SVMs\n",
    "from snapml import SupportVectorMachine\n",
    "snapml_svm_gpu = SupportVectorMachine(class_weight='balanced', random_state=42, use_gpu=True, fit_intercept=False)\n",
    "snapml_svm_cpu = SupportVectorMachine(class_weight='balanced', random_state=42, n_jobs=4, fit_intercept=False)\n",
    "t0 = time.time()\n",
    "model = snapml_svm_cpu.fit(X_train, y_train)\n",
    "snapml_time = time.time() - t0\n",
    "\n",
    "# Predict\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Get confidence score for probability\n",
    "y_pred_conf = svm.decision_function(X_test)\n",
    "\n",
    "# Evaluate hinge loss\n",
    "hinge_loss(y_test, y_pred_conf)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Terms / Jargons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decision boundary: the surface separating different predicted classes\n",
    "- linear classifier: a classifier that learns linear decision boundaries\n",
    "- linearly separable: a data set can be perfectly explained by a linear classifier\n",
    "- loss function : a function that provides penalty score that determines how poorly the model performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01.01.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/01.02.png\"  style=\"width: 400px, height: 300px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting, Underfitting, Bias variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overfitting : \n",
    "    - Model also memorises / trains on noise that resides within training data. \n",
    "    - Model performs well when evaluating on training data but does not perform well on unseen data\n",
    "    - High variance is responsible for this error because of also capturing noise.\n",
    "    - Diagnosis: cross-val prediction on test set has high error than prediction on train set\n",
    "    - Possible remedy : Decrease model complexity, gather more data, \n",
    "- Underfitting :\n",
    "    - Model is too simple to catch the pattern, model is not good enough to capture the underlying pattern.\n",
    "    - Model is bad on both training and unseen data\n",
    "    - Model is not flexibple enough to approximate the prediction values\n",
    "    - High bias is responsible for this error\n",
    "    - Diagnosis: cross-val prediction on train and test set are roughly equal but have very high errors that is undesirable\n",
    "    - Possible remedy : Increase model complexity, gather more features, \n",
    "- Bias-Variance trade-off :\n",
    "    - Generalization error = bias^2 + variance + irreducable error (noise)\n",
    "    - bias = error term that tells how on average real value is different from predicted value\n",
    "    - variance = error term that tells how predicted value varies over different training sets\n",
    "    - When model complexity increases, variance increases and bias decreases\n",
    "    - When model complexity decreases, variance decreases and bias increases\n",
    "    - The sweet spot is the minimised generalization error, which gives the optimised model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dot product of features and co-efficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Under the hood, prediction, y = dot product of co-efficient and X\n",
    "# changing intercept shifts the boundary up or down\n",
    "# changing co-efficient changes the sloper of the boundary\n",
    "y = model.coef_ @ X + model.intercept_ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression vs Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear regression:\n",
    "    - Finds a line that fits and aligns tightly with the data\n",
    "    - goal: line is the trend, any new value will appear *ON* the line\n",
    "    - Predicts the value itself\n",
    "    - Predicted value is a continuous value that exceeds 0 or 1\n",
    "- Logistic regression\n",
    "    - Finds a line / plane that separates the data by maximizing the distance\n",
    "    - goal : Line is a no-man's land. New value will appear on *EITHER SIDE* of the line\n",
    "    - predicts which class will the value fall in (sigmoid of the value).\n",
    "    - Predicted value is a discrete value that should be between 0 or 1\n",
    "    - construction: https://vitalflux.com/wp-content/uploads/2022/03/logistic-regression-model-3.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why cannot we use Linear regression in Linear classification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- regression loss : \n",
    "    - loss is higher when it is further away from true target value. \n",
    "    - loss happens both ways (since it is continuous value).\n",
    "    - squared loss curve perfectly captures this behavior\n",
    "    - Goal : Capture the closeness of values to the original continuous value on both side (positive or negative)\n",
    "- logistic loss: \n",
    "    - loss is higher only for incorrect classifications. \n",
    "    - loss happens in one direction (since it is binary classification.)\n",
    "    - squared loss captures only one direction correctly, the other direction mistakes as \"the perfect model also has squared loss, and so the perfect model is the worst model\"\n",
    "    - Goal : Capture the probability of the incorrectly classified values on incorrect side (sign does not matter as long as the dicrete value is an incorrect value. Correct value has 0 loss)\n",
    "    - we need to eliminate the mistaken side by introducing the logistic function, that only takes range from 0 to 1.\n",
    "- Hinge loss:\n",
    "    - Correct prediction has 0 loss\n",
    "    - Incorrect prediction has linear loss\n",
    "- 0-1 loss:\n",
    "    - It counts the number of misclassifications and averages it over the total number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.01.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.04.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization (minimization problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is how gradient descent works\n",
    "- We need to find the minimum value for a given function (eg:  loss function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define a cubic function to minimize: z = Ax^3 + By + C\n",
    "def cubic_function(x, A, B, C):\n",
    "    return A * x[0]**3 + B * x[1] + C\n",
    "\n",
    "# Coefficients for the cubic function\n",
    "A_coefficient = 2.0\n",
    "B_coefficient = -3.0\n",
    "C_constant = 5.0\n",
    "\n",
    "# Initial guess\n",
    "initial_guess = [1, 1]\n",
    "\n",
    "# Minimize the cubic function\n",
    "result = minimize(cubic_function, initial_guess, args=(A_coefficient, B_coefficient, C_constant), method='Nelder-Mead')\n",
    "\n",
    "# Print the result\n",
    "print(\"Minimum found at x:\", result.x)\n",
    "print(\"Minimum function value (z):\", result.fun)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log loss and hinge loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Mathematical functions for logistic and hinge losses\n",
    "def log_loss(raw_model_output):\n",
    "   return np.log(1+np.exp(-raw_model_output))\n",
    "def hinge_loss(raw_model_output):\n",
    "   return np.maximum(0,1-raw_model_output)\n",
    "\n",
    "# Create a grid of values and plot\n",
    "grid = np.linspace(-2,2,1000)\n",
    "plt.plot(grid, log_loss(grid), label='logistic')\n",
    "plt.plot(grid, hinge_loss(grid), label='hinge')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
