{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to include categorical features in the model building process can enhance performance as they may add information that contributes to prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "music_df = pd.read_csv(\"dataset/music_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of music_dummies: (1000, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, columns=['genre'], drop_first = True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have created `music_dummies`, containing binary features for each song's genre, it's time to build a ridge regression model to predict song popularity.\n",
    "\n",
    "The model will be evaluated by calculating the average RMSE, but first, you will need to convert the scores for each fold to positive values and take their square root. This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target value—\"`popularity`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 10.03309869053936\n",
      "Standard Deviation of the target array: 14.02156909907019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "# Create X and y\n",
    "X = music_dummies.drop(\"popularity\", axis = 1).values\n",
    "y = music_dummies[\"popularity\"].values\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha = .2)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the next three exercises, you are going to tidy the `music_df` dataset. You will create a pipeline to impute missing values and build a KNN classifier model, then use it to predict whether a song is of the \"`Rock`\" genre.\n",
    "\n",
    "In this exercise specifically, you will drop missing values accounting for less than 5% of the dataset, and convert the \"`genre`\" column into a binary feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "Shape of the `music_df`: (1000, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for song genre prediction: I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to build a pipeline. It will contain steps to impute missing values using the mean for each feature and build a KNN model for the classification of song genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for song genre prediction: II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having set up the steps of the pipeline in the previous exercise, you will now use it on the `music_df` dataset to classify the genre of songs. What makes pipelines so incredibly useful is the simple interface that they provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 12]\n",
      " [ 0 96]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = music_df.drop(\"genre\",axis=1).values\n",
    "y = music_df[\"genre\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centering and scaling for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have seen the benefits of scaling your data, you will use a pipeline to preprocess the `music_df` features and build a lasso regression model to predict a song's loudness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0025040064102566095\n"
     ]
    }
   ],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centering and scaling for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will bring together scaling and model building into a pipeline for cross-validation.\n",
    "\n",
    "Your task is to build a pipeline to scale features in the `music_df` dataset and perform grid search cross-validation using a logistic regression model with different values for the hyperparameter C. The target variable here is \"`genre`\", which contains binary values for rock as 1 and any other genre as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9275 \n",
      " {'logreg__C': 0.5793684210526315}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing regression model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have seen how to evaluate multiple models out of the box, you will build three regression models to predict a song's \"`energy`\" levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWZklEQVR4nO3df5BdZX3H8ffHTSIQELKTBTUkZIuxLKxC4RpliD9ShYnWGiiMJurgj+3EoIljW6w4azWtE6e0o1UjFqOkWms2/sBgGBVQsxG2iu4GY0iyhMlQlDWdEjDVxiGyid/+cZ4kl81N9myyu3f32c9r5s6e85znuec599z7uec+5+y9igjMzCxfz6p3B8zMbGQ56M3MMuegNzPLnIPezCxzDnozs8w56M3MMlcq6CUtkLRT0i5JNx2jzqskbZG0XdIPh9LWzMxGjga7jl5SA/AwcCXQB3QDiyNiR1Wds4AfAQsi4peSzo6Ix8u0NTOzkTWpRJ25wK6IeARA0jpgIVAd1m8GvhkRvwSIiMeH0PYo06dPj9mzZw9hM8zMJrbNmzc/ERFNtZaVCfoZwGNV833ASwfUeSEwWdIm4AzgUxHx7yXbHmX27Nn09PSU6JqZmQFI+sWxlpUJetUoGzjeMwm4DHg1cCrwY0n3l2x7qJNLgCUAs2bNKtEtMzMro8zJ2D5gZtX8ucDuGnXuiojfRcQTwL3AxSXbAhARqyOiEhGVpqaanz7MzOwElAn6bmCOpGZJU4BFwIYBdb4FvFzSJEmnUQzP9JZsa2ZmI2jQoZuIOCBpGXA30ACsiYjtkpam5bdGRK+ku4CtwB+AL0TENoBabUdoW8zMrIZBL6+sh0qlEj4Za2ZWnqTNEVGptcz/GWtmljkHvZlZ5hz0ZmaZK3MdvQ2BVOtfB4ZuLJ47MbPxyUE/zEp8d5BDfAwbjjdq718baxz0ZlX8Rm058hi9mVnmHPRmZplz0A9RY2Mjkk74BpxUe0k0NjbW+VEws/HEY/RDtHfv3rqP0Q7XlT0TTWNjI3v37j3p+znZx3/atGn8+te/Pul+mJXloLcJYyy8SYPfqG30eejGzCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8z58sohio88B1acWf8+2JCNhX13uB9mo8g/JThEY+FLrcZCH8ajsfK4jZV+WF78U4JmZhOYg97MLHMOejOzzDnozcwyVyroJS2QtFPSLkk31Vj+Kkm/kbQl3T5ctexRSQ+m8rF5htXMLGODXl4pqQG4BbgS6AO6JW2IiB0Dqt4XEa8/xt3Mj4gnTq6rZmZ2IspcRz8X2BURjwBIWgcsBAYG/YRR76+ZnTZtWl3XP57Ve9+B95+NvjJBPwN4rGq+D3hpjXqXS/o5sBu4MSK2p/IA7pEUwOciYvXJdLjeyvx49Gisx4auzGM6HPvP+87GmjJBX+uZP/CZ/ABwXkTsk/Q64A5gTlp2RUTslnQ28D1JD0XEvUetRFoCLAGYNWtW2f6POX6Rj2/ef5ajMidj+4CZVfPnUhy1HxYRv42IfWn6O8BkSdPT/O7093FgPcVQ0FEiYnVEVCKi0tTUNOQNMTOz2soEfTcwR1KzpCnAImBDdQVJz1X6zCtpbrrfJyVNlXRGKp8KXAVsG84NMDOz4xt06CYiDkhaBtwNNABrImK7pKVp+a3AdcANkg4ATwGLIiIknQOsT+8Bk4C1EXHXCG2LmZnV4C81MzPLgL/UzMxsAnPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpa5UkEvaYGknZJ2SbqpxvJXSfqNpC3p9uGybc3MbGRNGqyCpAbgFuBKoA/olrQhInYMqHpfRLz+BNuamdkIKXNEPxfYFRGPRMTTwDpgYcn7P5m2ZmY2DMoE/Qzgsar5vlQ20OWSfi7pu5IuGmJbJC2R1COpZ8+ePSW6ZWZmZZQJetUoiwHzDwDnRcTFwCrgjiG0LQojVkdEJSIqTU1NJbplZmZllAn6PmBm1fy5wO7qChHx24jYl6a/A0yWNL1MWzOz4SBpWG45KhP03cAcSc2SpgCLgA3VFSQ9V+kRkjQ33e+TZdqamQ2HiBj0VqZejga96iYiDkhaBtwNNABrImK7pKVp+a3AdcANkg4ATwGLonjEarYdoW0xM7MaNBbfwSqVSvT09NS7G2aWGUnZHrVL2hwRlVrL/J+xZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZjYuNDY2Dss18ifTvrGxsc6PwokZ9PJKM7OxYO/evXW/Yma8/kOVj+jNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PM+UvNzGxciI88B1acWf8+jEMOejMbF/T3vx0T314ZK+rahRPioRszs8w56M3MMlcq6CUtkLRT0i5JNx2n3kskHZR0XVXZo5IelLRFUs9wdNrMzMobdIxeUgNwC3Al0Ad0S9oQETtq1LsZuLvG3cyPiCeGob9mZjZEZY7o5wK7IuKRiHgaWAcsrFFvOXA78Pgw9s/MzE5SmaCfATxWNd+Xyg6TNAO4Bri1RvsA7pG0WdKSE+2omZmdmDKXV9b6NdyB1zh9EvhARBys8eO5V0TEbklnA9+T9FBE3HvUSoo3gSUAs2bNKtEtMzMro8wRfR8ws2r+XGD3gDoVYJ2kR4HrgM9KuhogInanv48D6ymGgo4SEasjohIRlaampqFsg5mZHUeZoO8G5khqljQFWARsqK4QEc0RMTsiZgPfAN4dEXdImirpDABJU4GrgG3DugVmZnZcgw7dRMQBScsorqZpANZExHZJS9PyWuPyh5wDrE/DOZOAtRFx18l328zMylK9/6W4lkqlEj09vuTezI6QNDa+AmEMZiaApM0RUam1zP8Za2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZpkrFfSSFkjaKWmXpJuOU+8lkg5Kum6obc3MbGRMGqyCpAbgFuBKoA/olrQhInbUqHczcPdQ25qZlSGpruufNm1aXdd/ogYNemAusCsiHgGQtA5YCAwM6+XA7cBLTqCtmdlxRcRJ34ekYbmf8abM0M0M4LGq+b5UdpikGcA1wK1DbWtmZiOrTNDX+qw08C3xk8AHIuLgCbQtKkpLJPVI6tmzZ0+JbpmZWRllhm76gJlV8+cCuwfUqQDr0vjZdOB1kg6UbAtARKwGVgNUKpWJ99nKzGyElDmi7wbmSGqWNAVYBGyorhARzRExOyJmA98A3h0Rd5RpazYedHR00NraSkNDA62trXR0dNS7S2alDRr0EXEAWEZxNU0v8LWI2C5pqaSlJ9L25Ls9/jgoxq+Ojg7a29tZtWoV+/fvZ9WqVbS3t3sf2vgREWPudtlll0VO1q5dG83NzbFx48Z4+umnY+PGjdHc3Bxr166td9eshIsuuig2btz4jLKNGzfGRRddVKce2YkqIi9PQE8cI1MVY/BSo0qlEj09PfXuxrBpbW1l1apVzJ8//3BZZ2cny5cvZ9u2bXXsmZXR0NDA/v37mTx58uGy/v5+TjnlFA4eHHj9gdXLcF1jPxYzsQxJmyOiUmuZvwJhFPT29jJv3rxnlM2bN4/e3t469ciGoqWlha6urmeUdXV10dLSUqceWS3HOpod6i1HDvpR4KAY39rb22lra6Ozs5P+/n46Oztpa2ujvb293l0zK6XM5ZV2kg4FxW233ca8efPo6uqira2NlStX1rtrVsLixYsBWL58Ob29vbS0tLBy5crD5WZjncfoR0lHRwcrV648HBTt7e0OCjMbNscbo3fQm5llwCdjzcwmMAe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWuVJBL2mBpJ2Sdkm6qcbyhZK2StoiqUfSvKplj0p68NCy4ey8mZkNbtAfB5fUANwCXAn0Ad2SNkTEjqpqPwA2RERIejHwNeCCquXzI+KJYey3mZmVVOaIfi6wKyIeiYingXXAwuoKEbEvjvz47FRg7P0QrZnZBFUm6GcAj1XN96WyZ5B0jaSHgG8D76xaFMA9kjZLWnKslUhakoZ9evbs2VOu92ZmNqgyQa8aZUcdsUfE+oi4ALga+GjVoisi4lLgtcB7JL2i1koiYnVEVCKi0tTUVKJbZmZWRpmg7wNmVs2fC+w+VuWIuBc4X9L0NL87/X0cWE8xFGRmZqOkTNB3A3MkNUuaAiwCNlRXkPQCSUrTlwJTgCclTZV0RiqfClwFbBvODTAzs+Mb9KqbiDggaRlwN9AArImI7ZKWpuW3AtcC10vqB54C3pSuwDkHWJ/eAyYBayPirhHaFjMzq0FHLpYZOyqVSvT0+JJ7M7OyJG2OiEqtZf7PWDOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwyVyroJS2QtFPSLkk31Vi+UNJWSVsk9UiaV7atmZmNrEGDXlIDcAvwWuBCYLGkCwdU+wFwcURcArwT+MIQ2pqZ2Qgqc0Q/F9gVEY9ExNPAOmBhdYWI2BcRkWanAlG2rZmZjawyQT8DeKxqvi+VPYOkayQ9BHyb4qi+dFszMxs5ZYJeNcriqIKI9RFxAXA18NGhtAWQtCSN7/fs2bOnRLfMzKyMMkHfB8ysmj8X2H2syhFxL3C+pOlDaRsRqyOiEhGVpqamEt0yM7MyygR9NzBHUrOkKcAiYEN1BUkvkKQ0fSkwBXiyTFszMxtZkwarEBEHJC0D7gYagDURsV3S0rT8VuBa4HpJ/cBTwJvSydmabUdoW8zMrAYduVhm7KhUKtHT01PvbpiZjRuSNkdEpdYy/2esmVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mWWvo6OD1tZWGhoaaG1tpaOjo95dGlWDfgWCmdl41tHRQXt7O7fddhvz5s2jq6uLtrY2ABYvXlzn3o0OfwWCmWWttbWVVatWMX/+/MNlnZ2dLF++nG3bttWxZ8PreF+B4KA3s6w1NDSwf/9+Jk+efLisv7+fU045hYMHD9axZ8PL33VjZhNWS0sLXV1dzyjr6uqipaWlTj0afQ56M8tae3s7bW1tdHZ20t/fT2dnJ21tbbS3t9e7a6PGJ2PNLGuHTrguX76c3t5eWlpaWLly5YQ5EQseozczy4LH6M3MJjAHvZlZ5hz0ZmaZc9CbmWXOQW9mlrkxedWNpD3AL+rdjxEyHXii3p2wE+b9N77lvP/Oi4imWgvGZNDnTFLPsS6BsrHP+298m6j7z0M3ZmaZc9CbmWXOQT/6Vte7A3ZSvP/Gtwm5/zxGb2aWOR/Rm5llLougl7SvRtlSSdePcj82Sdop6eeSuiVdMprrPx5Jb5B0U737MZZIOihpi6Rtku6UdFYqf76kbxyjzSZJE+6qjbGo1uveasti6EbSvog4fZTXKYrH7w9VZZuAGyOiR9I7gDdHxJXDsK6GiMjnp3DGiOrnjaQvAQ9HxMpB2mwi7eNR6KIdRz1e9+NVFkf0tUhaIenGNL1J0s2SfirpYUkvT+UNkv45HX1vlfSuVH66pB9IekDSg5IWpvLZknolfRZ4AJh5nC78GJiR2k2VtCat52dV93eapK+ldX9V0k8OHS1K2ifpHyT9BLhc0ltT/7dI+lzqe4OkL6Yj0gcl/VVq+15JO9L9rktlb5f0mTR9Xtq+renvrFT+RUmflvQjSY9Ium6Yd8tYVr2/ZkvalqZPlbTu0D4CTj3UQFJbej5tkvT5qse3SdLtaX93S7qiHhs0EUn68/Q6+pmk70s6J5W/Mr12tqRlZ0h6nqR7qz7VHcqFxen1tE3SzfXdomESEeP+BuyrUbaC4sgLYBPw8TT9OuD7aXoJ8KE0/WygB2im+EGW56Ty6cAuQMBs4A/Ay47Rj01AJU2/D/hYmv4Y8NY0fRbwMDAVuBH4XCpvBQ5UtQ/gjWm6BbgTmJzmPwtcD1wGfK9q/Welv7uBZw8oezvwmTR9J/C2NP1O4I40/UXg6xQHABcCu+q9b0fjeQM0pO1ekOZnA9vS9F8Da9L0iw/tI+D5wKNAIzAZuK/q8V0LzEvTs4Deem9rjrdjvO6ncWSk4i+rXvd3Alek6dPTa/xvgPaq58AZab/+EmhKdTYCV9d7W0/2NpF+Yeqb6e9mihcywFXAi6uOXM8E5gB9wMckvYIi2GcA56Q6v4iI+4+znq9ImkrxxLm0aj1vOPQJAziFIgDmAZ8CiIhtkrZW3c9B4PY0/WqKUO8uRow4FXic4sn7R5JWAd8G7kn1t6Z+3AHcUaOPlwN/kaa/DPxT1bI7ohiO2nHoaChjp0raQvF82Ax8r0adVwCfBoiIrVX7aC7ww4j4NYCkrwMvTMteA1yY9hXAcySdERH/NxIbYc9wLvBVSc8DpgD/lcr/E/iEpK8A34yIPkndwBpJkyme91sk/SmwKSL2AKT6r6D262jcyHbopobfp78HOfITigKWR8Ql6dYcEfcAb6F4R78sIi4B/ocinAF+N8h63kLxqWAtcEvVeq6tWs+siOhN5ceyP46Mywv4UlX7P46IFRGxF7iY4pPEe4AvpPp/ltZ9GbBZ0mBv6NUnan5fNX28/uXgqbR/z6MIhfcco16tE1nHe2yeBVxetb9mOORHzSqKT1YvAt5Fet1GxD9SHOGfCtwv6YKIuJcixH8FfFnFxRtZPucnUtDXcjdwQ3pHR9IL09H4mcDjEdEvaT5FEJQWEf3Ah4CXSWpJ61mudIgn6U9S1S7gjansQuBFx7jLHwDXSTo71W1M4+zTgWdFxO3A3wGXSnoWMDMiOoG/pRgqGnjC6kfAojT9ltSPCSsifgO8F7jx0HOhyr0UjxGSWimGbwB+CrxS0rT0RnptVZt7gGWHZjSGrr6aAM6kCG6Atx0qlHR+RDwYETdTDNFeIOk8itf554HbKD6B/4Riv06X1AAsBn44qlswAnIZujlNUl/V/CdKtvsCxcf2B1II7wGuBr4C3CmpB9gCPDTUDkXEU5I+TjEOvwz4JLA1redR4PUUY+1fSsMBP6MYcvlNjfvaIelDwD0pyPspjj6fAv4tlQF8kGLI6D8knUlxdPIvEfG/VcMIUITaGknvT9v8jqFuX24i4meSfk7xBnhf1aJ/pXiMt1I8F36a6v9K0scogmE3sIMj++69wC2pzSSKN4ulo7EdE0yt1/0K4OuSfgXcT/HpGuB96aDtIMW++i7Fvn6/pH5gH3B9RPy3pA8CnRSvn+9ExLdGZWtGUBaXV45X6YhhckTsl3Q+xZH7CyPi6Tp3zUqQdHpE7EtH9OspTtqur3e/zAbK5Yh+vDoN6EzDBQJucMiPKyskvYZiHPgexvkJO8uXj+jNzDI30U/Gmpllz0FvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpa5/wdJTUuVedZHygAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression \n",
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last exercise, linear regression and ridge appeared to produce similar results. It would be appropriate to select either of those models; however, you can check predictive performance on the test set to see if either one can outperform the other.\n",
    "\n",
    "You will use root mean squared error (RMSE) as the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Test Set RMSE: 0.3434546524072736\n",
      "Ridge Test Set RMSE: 0.34334299017652053\n",
      "Lasso Test Set RMSE: 0.3786246184767724\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "  # Fit the model to the training data\n",
    "  model = model.fit(X_train, y_train) # X_train_scaled\n",
    "  \n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test) # X_test_scaled\n",
    "  \n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing classification model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will be solving a classification problem where the \"`popularity`\" column in the `music_df` dataset has been converted to binary values, with 1 representing popularity more than or equal to the median for the \"`popularity`\" column, and 0 indicating popularity below the median.\n",
    "\n",
    "Your task is to build and visualize the results of three different models to classify whether a song is popular or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\88016\\anaconda3\\envs\\env_py\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train, y_train, cv=kf) # X_train_scaled\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for predicting song popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final exercise, you will build a pipeline to impute missing values, scale features, and perform hyperparameter tuning of a logistic regression model. The aim is to find the best parameters and accuracy when predicting song genre!\n",
    "\n",
    "All the models and objects required to build the pipeline have been preloaded for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'logreg__C': 0.556, 'logreg__solver': 'newton-cg'}, Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
