{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding optimal combination of parameters for a model\n",
    "- parameters: \n",
    "    - the ones that is set by the model after learning from dataset \n",
    "    - eg: co-efficients of linear regression, node decision by the decision trees\n",
    "    - accessible by attribute (in the attribute section in the documentation)\n",
    "- hyperparameters : \n",
    "    - the ones that we have the option to set before creating the model\n",
    "    - print the estimator to see what it contains\n",
    "    - accessible by parameter (in the parameter section in the documentation)\n",
    "- Silly things to do (some examples):\n",
    "    - Creating a random forest with just 2 or 3 trees\n",
    "    - 1,2 neighbors in knn algorithm\n",
    "    - increasing a hyperparameter by a small amount\n",
    "    - Be aware of conflicting hyperparameter choices (The 'newton-cg', 'sag' and 'lbfgs' solvers support only l2 penalties.)\n",
    "- Visualize if the hyperparameter has any effect:\n",
    "    - Graph of learning curve : hyperparameter on X-axis and accuracy on Y-axis\n",
    "- Problem: So many models can be build. But among these, find an optimal model that yields optimal result.\n",
    "- Solution: Train with a set of adjustable parameters and compare the results to find the optimal model\n",
    "- Rule of thumb : Cross validation is used to estimate the generalization performance.\n",
    "- Curse of dimensionality : exhaustively searching results in increase of dimensions with the increase of grid.\n",
    "- Best practice : Do this when you really need optimal solution since it does not make a bad model into a good model.\n",
    "- optimal hyperparameters = set of hyperparameters corresponding to the best CV score.\n",
    "- Some algorithms:\n",
    "    - Grid Search\n",
    "    - Random Search\n",
    "    - Bayesian Optimization\n",
    "    - Genetic Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, make_scorer\n",
    "\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state= 42)\n",
    "# Instantiate individual classifiers\n",
    "lr = LogisticRegression(random_state=42)\n",
    "knn = KNN()\n",
    "dt = DecisionTreeClassifier(random_state=42,max_depth=4, min_samples_leaf=0.16)\n",
    "classifiers = [('Logistic Regression', lr),\n",
    "                ('K Nearest Neighbours', knn),\n",
    "                ('Classification Tree', dt)]\n",
    "\n",
    "# Instantiate an ensemble VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble_model = VotingClassifier(estimators=classifiers)\n",
    "\n",
    "# Instantiate an ensemble VotingRegressor\n",
    "ensemble_model = VotingRegressor(estimators=regressors)\n",
    "\n",
    "# Instantiate an ensemble BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "ensemble_model = BaggingClassifier(base_estimator=dt, n_estimators=300,oob_score=True, n_jobs=-1)\n",
    "oob_accuracy = bc.oob_score_\n",
    "\n",
    "# Instantiate an ensemble BaggingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "base_regressor = DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)\n",
    "ensemble_model = BaggingRegressor(base_estimator=base_regressor, n_estimators=300, oob_score=True, n_jobs=-1)\n",
    "oob_score = ensemble_model.oob_score_\n",
    "\n",
    "# Instantiate an ensemble RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "ensemble_model = RandomForestRegressor(n_estimators=400, min_samples_leaf=0.12, random_state=42)\n",
    "\n",
    "# Instantiate an ensemble RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ensemble_model = RandomForestClassifier(n_estimators=400, random_state=42)\n",
    "\n",
    "# Instantiate an ensemble AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ensemble_model = AdaBoostClassifier(base_estimator=dt, n_estimators=100) # dt is weak, has max depth of 1\n",
    "y_pred_proba = ensemble_model.predict_proba(X_test)[:,1]\n",
    "# Evaluate testing roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "adb_clf_roc_auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Instantiate an ensemble GradientBoostingRegressor, (max_features=0.2, subsample=0.8) makes it stochastic gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "ensemble_model = GradientBoostingRegressor(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=42)\n",
    "\n",
    "# Train using traing set\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "# Predict with test set\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "# Evaluate accuracy for classification\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# Evaluate RMSE for regression\n",
    "rmse = MSE(y_test, y_pred)**(1/2)\n",
    "# Visualize features importances\n",
    "importances = pd.Series(ensemble_model.feature_importances_, index = X.columns)\n",
    "sorted_importances = importances.sort_values()\n",
    "sorted_importances.plot(kind='barh', color='lightgreen')\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "# See what parameters can be tuned\n",
    "ryour_dt_model.get_params()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "params_dt = {\n",
    "    'max_depth': [3, 4,5, 6],\n",
    "    'min_samples_leaf': [0.04, 0.06, 0.08],\n",
    "    'max_features': [0.2, 0.4,0.6, 0.8]\n",
    "}\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "model_cv = GridSearchCV(estimator=your_dt_model,\n",
    "    param_grid=params_dt,\n",
    "    cv=kf, # scorer = mae_scorer\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1)\n",
    "model_cv.fit(X_train, y_train)\n",
    "best_hyperparams = model_cv.best_params_# Get the parameters with best result\n",
    "best_model = model_cv.best_estimator_ # Get the best model\n",
    "best_model.get_params() # See all parameters\n",
    "y_pred = best_model.predict(X_test) # predict with best model\n",
    "best_score = best_model.best_score_\n",
    "model_cv.cv_results_ # See all information from dictionary\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(best_model, 'my_best_model.pkl') # Save the model in pkl file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Split into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "\n",
    "# Make sure to take into account the class imbalance \n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "w_train = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "# Train the classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "tree_clf.fit(X_Train,y_Train, sample_weight=w_train)\n",
    "\n",
    "# Alternative approach : Train the classifier with snapml (offers multi-threaded CPU/GPU training)\n",
    "from snapml import DecisionTreeClassifier\n",
    "snapml_dt_gpu = DecisionTreeClassifier(max_depth=4, random_state=45, use_gpu=True)\n",
    "snapml_dt_cpu = DecisionTreeClassifier(max_depth=4, random_state=45, n_jobs=4)\n",
    "snapml_dt.fit(X_train, y_train, sample_weight=w_train)\n",
    "# Predict\n",
    "y_pred = tree_clf.predict(X_Test)\n",
    "\n",
    "### Inspecting a random forest\n",
    "# Pull out one tree from the forest (If decision tree is a random forest)\n",
    "chosen_tree = randomforest_model.estimators_[7] # You can visualize it with (graphviz & pydotplus)\n",
    "# Extract node decisions\n",
    "split_column = chosen_tree.tree_.feature[0] # Get the first column it split on\n",
    "split_column_name = X_train.columns[split_column] # Name of the column\n",
    "split_value = chosen_tree.tree_.threshold[1] # Get the theshold value it split on\n",
    "\n",
    "# Compute predicted probabilities\n",
    "y_pred_prob = tree_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Evaluate tree\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "accuracy_score(y_testset, predTree)\n",
    "roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Visualize the graph using plot_tree\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(chosen_tree, feature_names=X_train.columns, filled=True, rounded=True, fontsize=10)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
