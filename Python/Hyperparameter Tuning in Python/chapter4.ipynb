{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Coarse to Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to undertake the first part of a Coarse to Fine search. This involves analyzing the results of an initial random search that took place over a large search space, then deciding what would be the next logical step to make your hyperparameter search finer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "a = list(range(1,6))\n",
    "b = list(range(3,17))\n",
    "c= np.linspace(0.01, 1.33, 143)\n",
    "combinations_list = list(product(a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10010\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confirm the size of the combinations_list\n",
    "print(len(combinations_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_hyperparameter(name):\n",
    "#   plt.clf()\n",
    "#   plt.scatter(results_df[name],results_df['accuracy'], c=['blue']*500)\n",
    "#   plt.gca().set(xlabel='{}'.format(name), ylabel='accuracy', title='Accuracy for different {}s'.format(name))\n",
    "#   plt.gca().set_ylim([0,100])\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confirm the size of the combinations_list\n",
    "# print(len(combinations_list))\n",
    "\n",
    "# # Sort the results_df by accuracy and print the top 10 rows\n",
    "# print(results_df.sort_values(by='accuracy', ascending=False).head(10))\n",
    "\n",
    "# # Confirm which hyperparameters were used in this search\n",
    "# print(results_df.columns)\n",
    "\n",
    "# # Call visualize_hyperparameter() with each hyperparameter in turn\n",
    "# visualize_hyperparameter(\"max_depth\")\n",
    "# visualize_hyperparameter(\"min_samples_leaf\")\n",
    "# visualize_hyperparameter(\"learn_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coarse to Fine Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now visualize the first random search undertaken, construct a tighter grid and check the results. You will have available:\n",
    "\n",
    "- `results_df` - a DataFrame that has the hyperparameter combination and the resulting accuracy of all 500 trials. Only the hyperparameters that had the strongest visualizations from the previous exercise are included (max_depth and learn_rate)\n",
    "- `visualize_first()` - This function takes no arguments but will visualize each of your hyperparameters against accuracy for your first random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_first():\n",
    "#   for name in results_df.columns[0:2]:\n",
    "#     plt.clf()\n",
    "#     plt.scatter(results_df[name],results_df['accuracy'], c=['blue']*500)\n",
    "#     plt.gca().set(xlabel='{}'.format(name), ylabel='accuracy', title='Accuracy for different {}s'.format(name))\n",
    "#     plt.gca().set_ylim([0,100])\n",
    "#     x_line = 20\n",
    "#     if name == \"learn_rate\":\n",
    "#       \tx_line = 1\n",
    "#     plt.axvline(x=x_line, color=\"red\", linewidth=4)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_second():\n",
    "#   for name in results_df2.columns[0:2]:\n",
    "#     plt.clf()\n",
    "#     plt.scatter(results_df2[name],results_df2['accuracy'], c=['blue']*1000)\n",
    "#     plt.gca().set(xlabel='{}'.format(name), ylabel='accuracy', title='Accuracy for different {}s'.format(name))\n",
    "#     plt.gca().set_ylim([0,100])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the provided function to visualize the first results\n",
    "# visualize_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create some combinations lists & combine\n",
    "# max_depth_list = list(range(1, 21))\n",
    "# learn_rate_list = np.linspace(0.001, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Call the function to visualize the second results\n",
    "# visualize_second()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Rule in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will undertake a practical example of setting up Bayes formula, obtaining new evidence and updating your 'beliefs' in order to get a more accurate result. The example will relate to the likelihood that someone will close their account for your online software product.\n",
    "\n",
    "These are the probabilities we know:\n",
    "\n",
    "- 7% (0.07) of people are likely to close their account next month\n",
    "- 15% (0.15) of people with accounts are unhappy with your product (you don't know who though!)\n",
    "- 35% (0.35) of people who are likely to close their account are unhappy with your product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16333333333333336\n"
     ]
    }
   ],
   "source": [
    "# Assign probabilities to variables \n",
    "p_unhappy = 0.15\n",
    "p_unhappy_close = 0.35\n",
    "\n",
    "# Probabiliy someone will close\n",
    "p_close = 0.07\n",
    "\n",
    "# Probability unhappy person will close\n",
    "p_close_unhappy = (p_unhappy_close * p_close) / p_unhappy\n",
    "print(p_close_unhappy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Hyperparameter tuning with Hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n this example you will set up and run a Bayesian hyperparameter optimization process using the package Hyperopt (already imported as hp for you). You will set up the domain (which is similar to setting up the grid for a grid search), then set up the objective function. Finally, you will run the optimizer over 20 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"dataset/credit-card-full.csv\")\n",
    "# df.head()\n",
    "# df.select_dtypes(include=\"int\")\n",
    "# df['default payment next month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "y= df['default payment next month']\n",
    "X = df.drop('default payment next month', axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [09:23<00:00, 28.16s/trial, best loss: 0.17829166666666674]\n",
      "{'learning_rate': 0.11650414294836509, 'max_depth': 3.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "# Set up space dictionary with specified hyperparameters\n",
    "space = {'max_depth': hp.quniform('max_depth', 2, 10, 3),'learning_rate': hp.uniform('learning_rate', 0.1,0.5)}\n",
    "\n",
    "# Set up objective function\n",
    "def objective(params):\n",
    "    params = {'max_depth': int(params['max_depth']),'learning_rate': params['learning_rate']}\n",
    "    gbm_clf = GradientBoostingClassifier(n_estimators=100, **params) \n",
    "    best_score = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=2, n_jobs=4).mean()\n",
    "    loss = 1 - best_score\n",
    "    return loss\n",
    "\n",
    "# Run the algorithm\n",
    "best = fmin(fn=objective,space=space, max_evals=20, rstate=np.random.default_rng(42), algo=tpe.suggest)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Hyperparameter Tuning with TPOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to undertake a simple example of genetic hyperparameter tuning. TPOT is a very powerful library that has a lot of features. You're just scratching the surface in this lesson, but you are highly encouraged to explore in your own time.\n",
    "\n",
    "This is a very small example. In real life, TPOT is designed to be run for many hours to find the best model. You would have a much larger population and offspring size as well as hundreds more generations to find a good model.\n",
    "\n",
    "You will create the estimator, fit the estimator to the training data and then score this on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Generation 1 - Current best internal CV score: 0.8185\n",
      "                                                                            \n",
      "Generation 2 - Current best internal CV score: 0.8185\n",
      "                                                                            \n",
      "Generation 3 - Current best internal CV score: 0.8188333333333333\n",
      "                                                                            \n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=False, criterion=entropy, max_features=0.6000000000000001, min_samples_leaf=17, min_samples_split=11, n_estimators=100)\n",
      "0.8191666666666667\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "# Assign the values outlined to the inputs\n",
    "number_generations = 3\n",
    "population_size = 4\n",
    "offspring_size = 3\n",
    "scoring_function = 'accuracy'\n",
    "\n",
    "# Create the tpot classifier\n",
    "tpot_clf = TPOTClassifier(generations=number_generations, population_size=population_size,\n",
    "                          offspring_size=3, scoring=scoring_function,\n",
    "                          verbosity=2, random_state=2, cv=2)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing TPOT's stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now see the random nature of TPOT by constructing the classifier with different random states and seeing what model is found to be best by the algorithm. This assists to see that TPOT is quite unstable when not run for a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Generation 1 - Current best internal CV score: 0.8200416666666667\n",
      "                                                                            \n",
      "Generation 2 - Current best internal CV score: 0.8200416666666667\n",
      "                                                                            \n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.6000000000000001, min_samples_leaf=15, min_samples_split=10, n_estimators=100)\n",
      "0.8198333333333333\n"
     ]
    }
   ],
   "source": [
    "# Create the tpot classifier \n",
    "tpot_clf = TPOTClassifier(generations=2, population_size=4, offspring_size=3, scoring='accuracy', cv=2,\n",
    "                          verbosity=2, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Generation 1 - Current best internal CV score: 0.8113333333333332\n",
      "                                                                            \n",
      "Generation 2 - Current best internal CV score: 0.8113333333333332\n",
      "                                                                            \n",
      "Best pipeline: LogisticRegression(RobustScaler(input_matrix), C=0.5, dual=False, penalty=l2)\n",
      "0.8023333333333333\n"
     ]
    }
   ],
   "source": [
    "# Create the tpot classifier \n",
    "tpot_clf = TPOTClassifier(generations=2, population_size=4, offspring_size=3, scoring='accuracy', cv=2,\n",
    "                          verbosity=2, random_state=122)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Generation 1 - Current best internal CV score: 0.8160000000000001\n",
      "                                                                            \n",
      "Generation 2 - Current best internal CV score: 0.8189583333333333\n",
      "                                                                            \n",
      "Best pipeline: GradientBoostingClassifier(RFE(input_matrix, criterion=entropy, max_features=0.8500000000000001, n_estimators=100, step=0.6000000000000001), learning_rate=0.5, max_depth=1, max_features=0.7000000000000001, min_samples_leaf=10, min_samples_split=17, n_estimators=100, subsample=0.6000000000000001)\n",
      "0.8121666666666667\n"
     ]
    }
   ],
   "source": [
    "# Create the tpot classifier \n",
    "tpot_clf = TPOTClassifier(generations=2, population_size=4, offspring_size=3, scoring='accuracy', cv=2,\n",
    "                          verbosity=2, random_state=99)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
