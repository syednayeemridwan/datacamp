{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly Sample Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To undertake a random search, we firstly need to undertake a random sampling of our hyperparameter space.\n",
    "\n",
    "In this exercise, you will firstly create some lists of hyperparameters that can be zipped up to a list of lists. Then you will randomly sample hyperparameter combinations in preparation for running a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"dataset/credit-card-full.csv\")\n",
    "# df.head()\n",
    "# df.select_dtypes(include=\"int\")\n",
    "# df['default payment next month']\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "y= df['default payment next month']\n",
    "X = df.drop('default payment next month', axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "# log_reg_clf = LogisticRegression()\n",
    "# log_reg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1555778894472362, 20], [0.968391959798995, 25], [0.3918592964824121, 30], [1.3577386934673366, 13], [1.3802010050251257, 12], [0.12979899497487438, 24], [0.5790452261306532, 16], [1.4101507537688442, 18], [1.1406030150753768, 40], [0.287035175879397, 16], [0.9384422110552764, 14], [1.4401005025125628, 12], [1.245427135678392, 38], [0.039949748743718594, 15], [1.1106532663316582, 31], [1.0432663316582915, 29], [1.327788944723618, 37], [0.03246231155778895, 28], [1.4026633165829145, 19], [1.2604020100502513, 21], [0.6314572864321608, 35], [0.6314572864321608, 17], [0.09236180904522612, 13], [0.19718592964824122, 31], [0.15974874371859296, 13], [0.38437185929648243, 33], [0.968391959798995, 26], [1.4775376884422111, 37], [1.455075376884422, 32], [1.2379396984924622, 24], [1.1406030150753768, 33], [0.2271356783919598, 27], [0.7587437185929649, 34], [0.6239698492462311, 38], [1.327788944723618, 18], [0.6838693467336683, 32], [0.7287939698492463, 15], [0.6389447236180904, 34], [0.5940201005025125, 28], [0.5640703517587939, 34], [1.0881909547738693, 32], [0.33195979899497485, 11], [0.5790452261306532, 25], [1.0208040201005024, 35], [0.8485929648241206, 26], [0.12231155778894472, 10], [0.7737185929648241, 32], [0.9084924623115578, 14], [1.0058291457286432, 14], [0.08487437185929647, 26], [0.48170854271356783, 18], [0.23462311557788945, 16], [1.1256281407035176, 14], [0.818643216080402, 38], [0.33195979899497485, 19], [0.8560804020100502, 17], [0.5191457286432161, 34], [1.2079899497487436, 40], [0.05492462311557789, 10], [0.05492462311557789, 21], [1.0282914572864321, 14], [0.9758793969849247, 25], [1.4176381909547737, 33], [0.26457286432160804, 13], [0.8935175879396985, 22], [0.2121608040201005, 40], [0.2945226130653266, 18], [0.21964824120603016, 39], [0.33195979899497485, 32], [0.6389447236180904, 30], [0.9010050251256281, 11], [0.039949748743718594, 14], [0.5565829145728644, 36], [0.4592462311557789, 34], [0.24959798994974874, 22], [1.1855276381909547, 33], [0.1672361809045226, 39], [1.4700502512562814, 31], [1.095678391959799, 21], [0.06241206030150754, 28], [0.09984924623115578, 10], [0.9159798994974874, 23], [1.0807035175879396, 33], [0.9833668341708542, 18], [0.5940201005025125, 36], [1.07321608040201, 21], [0.1672361809045226, 38], [0.9758793969849247, 15], [1.3951758793969848, 22], [1.3577386934673366, 29], [1.4475879396984925, 30], [1.0208040201005024, 26], [0.414321608040201, 38], [0.2421105527638191, 36], [0.33195979899497485, 36], [0.3768844221105528, 33], [0.3918592964824121, 18], [1.4775376884422111, 32], [0.9234673366834171, 36], [1.1106532663316582, 23], [0.6763819095477387, 11], [0.31698492462311556, 11], [1.1705527638190953, 21], [0.3394472361809045, 38], [0.34693467336683415, 11], [1.0208040201005024, 21], [0.04743718592964824, 22], [0.9983417085427135, 40], [1.0357788944723618, 11], [0.42180904522613066, 18], [0.18969849246231157, 18], [0.968391959798995, 27], [0.5865326633165829, 10], [0.968391959798995, 12], [0.36939698492462314, 32], [1.3427638190954774, 32], [0.2945226130653266, 39], [0.287035175879397, 20], [0.12231155778894472, 40], [0.6763819095477387, 32], [1.4625628140703517, 17], [0.4592462311557789, 22], [0.9159798994974874, 25], [0.8560804020100502, 20], [0.36939698492462314, 25], [0.12231155778894472, 23], [1.3802010050251257, 39], [0.5940201005025125, 30], [0.27954773869346733, 24], [0.6838693467336683, 10], [0.6015075376884422, 35], [0.6988442211055276, 27], [0.5041708542713568, 35], [1.4775376884422111, 35], [1.2828643216080402, 38], [0.31698492462311556, 15], [0.8785427135678392, 15], [0.4742211055276382, 34], [0.9983417085427135, 30], [0.15974874371859296, 14], [0.2570854271356784, 30], [1.29035175879397, 11], [0.45175879396984925, 19], [1.0582412060301507, 15], [0.4742211055276382, 19], [0.7437688442211056, 21], [0.15974874371859296, 18], [0.024974874371859294, 12], [1.1331155778894473, 20], [0.691356783919598, 39], [0.7138190954773869, 30], [0.8411055276381909, 32], [1.455075376884422, 13], [1.4775376884422111, 27], [0.9833668341708542, 28], [0.9758793969849247, 34], [0.3394472361809045, 26], [0.6389447236180904, 26], [1.4625628140703517, 11], [0.07738693467336683, 19], [1.29035175879397, 13], [0.5116582914572865, 24], [0.7063316582914573, 12], [0.668894472361809, 28], [1.1855276381909547, 21], [0.11482412060301507, 27], [0.9534170854271357, 20], [0.7512562814070352, 25], [0.9983417085427135, 11], [0.7063316582914573, 34], [1.0282914572864321, 22], [0.9010050251256281, 20], [0.24959798994974874, 27], [0.3544221105527638, 17], [0.12231155778894472, 34], [1.4251256281407034, 20], [0.9908542713567839, 29], [1.4475879396984925, 24], [0.36190954773869344, 18], [1.013316582914573, 22], [0.6614070351758794, 22], [1.0657286432160804, 14], [0.3768844221105528, 26], [0.4442713567839196, 26], [0.45175879396984925, 21], [0.12231155778894472, 38], [0.7662311557788944, 22], [1.0432663316582915, 35], [1.4401005025125628, 10], [0.8261306532663316, 24], [1.4251256281407034, 25], [0.06989949748743718, 33], [0.06241206030150754, 20], [1.3652261306532663, 18], [1.0657286432160804, 15], [1.1181407035175879, 19], [1.3876884422110551, 40], [0.14477386934673367, 37], [1.3203015075376885, 25], [1.0058291457286432, 26], [0.06241206030150754, 19], [0.6389447236180904, 28], [1.0432663316582915, 10], [1.4176381909547737, 39], [1.013316582914573, 27], [0.3244723618090452, 31], [1.2753768844221105, 11], [0.17472361809045225, 40], [0.06241206030150754, 36], [0.7886934673366834, 11], [1.2154773869346733, 22], [0.968391959798995, 19], [1.1555778894472362, 28], [0.2121608040201005, 34], [1.4251256281407034, 19], [1.1106532663316582, 17], [0.7587437185929649, 35], [0.2720603015075377, 24], [0.9159798994974874, 11], [1.3802010050251257, 18], [0.6838693467336683, 31], [0.06241206030150754, 31], [0.8485929648241206, 35], [1.4026633165829145, 36], [1.2379396984924622, 38], [0.3094974874371859, 11], [0.42180904522613066, 10], [1.4925125628140703, 10], [0.3918592964824121, 17], [0.414321608040201, 27], [0.9309547738693467, 19], [1.372713567839196, 13], [0.818643216080402, 16], [1.4026633165829145, 28], [0.7512562814070352, 37], [0.2271356783919598, 21], [1.1106532663316582, 37], [1.3352763819095477, 16], [0.2271356783919598, 29], [0.5715577889447236, 23], [0.7886934673366834, 39], [1.1331155778894473, 29], [1.455075376884422, 24], [0.4442713567839196, 33], [0.7812060301507537, 23], [1.4475879396984925, 28], [1.1181407035175879, 26], [0.6239698492462311, 31], [0.6164824120603015, 11], [0.7886934673366834, 22]]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "# Create a list of values for the learning_rate hyperparameter\n",
    "learn_rate_list = list(np.linspace(0.01,1.5,200))\n",
    "\n",
    "# Create a list of values for the min_samples_leaf hyperparameter\n",
    "min_samples_list = list(range(10,41))\n",
    "\n",
    "# Combination list\n",
    "combinations_list = [list(x) for x in product(learn_rate_list, min_samples_list)]\n",
    "\n",
    "# Sample hyperparameter combinations for a random search.\n",
    "random_combinations_index = np.random.choice(range(0, len(combinations_list)), 250, replace=False)\n",
    "combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
    "\n",
    "# Print the result\n",
    "print(combinations_random_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly Search with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solidify your knowledge of random sampling, let's try a similar exercise but using different hyperparameters and a different algorithm.\n",
    "\n",
    "As before, create some lists of hyperparameters that can be zipped up to a list of lists. You will use the hyperparameters `criterion`, `max_depth` and `max_features` of the random forest algorithm. Then you will randomly sample hyperparameter combinations in preparation for running a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['gini', None, 47], ['gini', 'log2', 7], ['gini', 'sqrt', 19], ['gini', 'sqrt', 27], ['gini', 'log2', 47], ['entropy', None, 7], ['gini', None, 10], ['gini', 'sqrt', 53], ['entropy', None, 10], ['gini', 'log2', 20], ['gini', 'sqrt', 37], ['gini', 'log2', 29], ['entropy', None, 55], ['entropy', 'auto', 23], ['gini', 'sqrt', 46], ['gini', 'auto', 43], ['entropy', 'auto', 32], ['gini', 'log2', 48], ['entropy', 'log2', 42], ['entropy', 'auto', 33], ['entropy', 'sqrt', 50], ['gini', None, 19], ['entropy', None, 21], ['entropy', 'log2', 54], ['gini', 'log2', 13], ['gini', None, 49], ['entropy', 'log2', 50], ['gini', 'log2', 39], ['entropy', 'auto', 46], ['entropy', None, 3], ['entropy', None, 26], ['gini', 'log2', 54], ['gini', None, 38], ['gini', 'sqrt', 36], ['entropy', 'auto', 24], ['gini', 'sqrt', 38], ['entropy', None, 4], ['entropy', None, 37], ['gini', 'sqrt', 28], ['gini', 'log2', 41], ['gini', 'auto', 42], ['entropy', 'log2', 51], ['entropy', None, 48], ['entropy', None, 53], ['entropy', None, 32], ['entropy', None, 36], ['entropy', None, 33], ['gini', None, 55], ['entropy', 'auto', 55], ['entropy', None, 25], ['gini', None, 31], ['entropy', None, 28], ['gini', None, 13], ['entropy', 'log2', 19], ['entropy', 'log2', 25], ['gini', 'auto', 44], ['gini', 'log2', 5], ['entropy', None, 49], ['entropy', 'sqrt', 33], ['entropy', None, 17], ['entropy', 'auto', 30], ['entropy', 'log2', 55], ['entropy', None, 44], ['entropy', 'sqrt', 45], ['entropy', 'auto', 53], ['entropy', 'sqrt', 12], ['gini', 'log2', 43], ['gini', None, 29], ['gini', 'log2', 40], ['gini', 'sqrt', 6], ['gini', 'auto', 41], ['entropy', 'auto', 28], ['gini', 'auto', 52], ['entropy', 'log2', 32], ['gini', 'auto', 15], ['entropy', None, 20], ['entropy', 'log2', 41], ['gini', 'log2', 32], ['entropy', 'log2', 21], ['gini', 'sqrt', 51], ['gini', None, 4], ['entropy', 'auto', 17], ['entropy', None, 19], ['gini', 'sqrt', 50], ['entropy', 'sqrt', 20], ['entropy', 'auto', 15], ['entropy', 'log2', 7], ['gini', 'log2', 3], ['gini', 'sqrt', 11], ['gini', 'log2', 9], ['gini', None, 41], ['gini', 'auto', 40], ['gini', 'auto', 39], ['entropy', 'sqrt', 29], ['gini', 'sqrt', 5], ['entropy', None, 14], ['gini', None, 48], ['entropy', 'sqrt', 22], ['entropy', 'auto', 26], ['entropy', 'auto', 5], ['gini', 'sqrt', 21], ['gini', None, 54], ['entropy', 'log2', 17], ['entropy', 'auto', 51], ['entropy', 'log2', 34], ['entropy', 'sqrt', 13], ['entropy', 'auto', 16], ['gini', 'auto', 31], ['entropy', None, 43], ['gini', 'auto', 6], ['gini', 'log2', 4], ['entropy', 'log2', 29], ['gini', None, 33], ['gini', 'log2', 17], ['entropy', 'sqrt', 35], ['entropy', 'sqrt', 32], ['entropy', 'log2', 22], ['gini', 'auto', 47], ['gini', 'log2', 49], ['entropy', 'sqrt', 25], ['gini', 'log2', 6], ['entropy', 'auto', 10], ['entropy', 'log2', 11], ['gini', 'log2', 25], ['gini', 'auto', 30], ['entropy', 'sqrt', 31], ['entropy', 'auto', 8], ['gini', 'log2', 12], ['gini', None, 40], ['gini', 'sqrt', 12], ['gini', 'log2', 11], ['entropy', 'sqrt', 34], ['entropy', None, 15], ['entropy', 'log2', 3], ['entropy', 'auto', 18], ['gini', None, 24], ['gini', 'auto', 46], ['gini', 'log2', 15], ['gini', None, 26], ['gini', 'auto', 54], ['entropy', 'log2', 13], ['gini', 'log2', 10], ['gini', 'auto', 4], ['gini', 'auto', 9], ['gini', None, 21], ['entropy', 'log2', 6], ['entropy', 'sqrt', 53], ['gini', 'auto', 19], ['gini', 'sqrt', 20], ['entropy', 'log2', 39]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Create lists for criterion and max_features\n",
    "criterion_list = ['gini' , 'entropy']\n",
    "max_feature_list = [\"auto\", \"sqrt\", \"log2\", None]\n",
    "\n",
    "# Create a list of values for the max_depth hyperparameter\n",
    "max_depth_list = list(range(3,56))\n",
    "\n",
    "# Combination list\n",
    "combinations_list = [list(x) for x in product(criterion_list, max_feature_list, max_depth_list)]\n",
    "\n",
    "# Sample hyperparameter combinations for a random search\n",
    "combinations_random_chosen = random.sample(combinations_list, 150)\n",
    "\n",
    "# Print the result\n",
    "print(combinations_random_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing a Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the search space of random search allows you to easily see the coverage of this technique and therefore allows you to see the effect of your sampling on the search space.\n",
    "\n",
    "In this exercise you will use several different samples of hyperparameter combinations and produce visualizations of the search space.\n",
    "\n",
    "The function `sample_and_visualize_hyperparameters()` takes a single argument (number of combinations to sample) and then randomly samples hyperparameter combinations, just like you did in the last exercise! The function will then visualize the combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def sample_and_visualize_hyperparameters(n_samples):\n",
    "\n",
    "  # If asking for all combinations, just return the entire list.\n",
    "  if n_samples == len(combinations_list):\n",
    "    combinations_random_chosen = combinations_list\n",
    "  else:\n",
    "    combinations_random_chosen = []\n",
    "    random_combinations_index = np.random.choice(range(0, len(combinations_list)), n_samples, replace=False)\n",
    "    combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
    "    \n",
    "  # Pull out the X and Y to plot\n",
    "  rand_y, rand_x = [x[0] for x in combinations_random_chosen], [x[1] for x in combinations_random_chosen]\n",
    "\n",
    "  # Plot \n",
    "  plt.clf() \n",
    "  plt.scatter(rand_y, rand_x, c=['blue']*len(combinations_random_chosen))\n",
    "  plt.gca().set(xlabel='learn_rate', ylabel='min_samples_leaf', title='Random Search Hyperparameters')\n",
    "  plt.gca().set_xlim(x_lims)\n",
    "  plt.gca().set_ylim(y_lims)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confirm how many hyperparameter combinations & print\n",
    "# number_combs = len(combinations_list)\n",
    "# print(number_combs)\n",
    "\n",
    "# # Sample and visualise specified combinations\n",
    "# for x in [50, 500, 1500]:\n",
    "#     sample_and_visualize_hyperparameters(x)\n",
    "    \n",
    "# # Sample all the hyperparameter combinations & visualise\n",
    "# sample_and_visualize_hyperparameters(number_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearchCV inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test your knowledge of how RandomizedSearchCV differs from GridSearchCV.\n",
    "\n",
    "You can check the documentation on Scitkit Learn's website to compare these two functions.\n",
    "\n",
    "Which of these parameters is only for a `RandomizedSearchCV`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n_iter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The RandomizedSearchCV Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the `GridSearchCV` library from Scikit Learn, `RandomizedSearchCV` provides many useful features to assist with efficiently undertaking a random search. You're going to create a `RandomizedSearchCV` object, making the small adjustment needed from the `GridSearchCV` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-4,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.1       , 0.11275168, 0.12550336, 0.13825503, 0.15100671,\n",
       "       0.16375839, 0.17651007, 0.18926174, 0.20201342, 0.2147651 ,\n",
       "       0.22751678, 0.24026846, 0.25302013, 0.26577181, 0.27852349,\n",
       "       0.29127517, 0.30402685, 0.31677852, 0.3295302 , 0.34228188,\n",
       "       0.35503356, 0.36778523,...\n",
       "       1.75771812, 1.7704698 , 1.78322148, 1.79597315, 1.80872483,\n",
       "       1.82147651, 1.83422819, 1.84697987, 1.85973154, 1.87248322,\n",
       "       1.8852349 , 1.89798658, 1.91073826, 1.92348993, 1.93624161,\n",
       "       1.94899329, 1.96174497, 1.97449664, 1.98724832, 2.        ]),\n",
       "                                        &#x27;min_samples_leaf&#x27;: [20, 21, 22, 23, 24,\n",
       "                                                             25, 26, 27, 28, 29,\n",
       "                                                             30, 31, 32, 33, 34,\n",
       "                                                             35, 36, 37, 38, 39,\n",
       "                                                             40, 41, 42, 43, 44,\n",
       "                                                             45, 46, 47, 48, 49, ...]},\n",
       "                   return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-4,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.1       , 0.11275168, 0.12550336, 0.13825503, 0.15100671,\n",
       "       0.16375839, 0.17651007, 0.18926174, 0.20201342, 0.2147651 ,\n",
       "       0.22751678, 0.24026846, 0.25302013, 0.26577181, 0.27852349,\n",
       "       0.29127517, 0.30402685, 0.31677852, 0.3295302 , 0.34228188,\n",
       "       0.35503356, 0.36778523,...\n",
       "       1.75771812, 1.7704698 , 1.78322148, 1.79597315, 1.80872483,\n",
       "       1.82147651, 1.83422819, 1.84697987, 1.85973154, 1.87248322,\n",
       "       1.8852349 , 1.89798658, 1.91073826, 1.92348993, 1.93624161,\n",
       "       1.94899329, 1.96174497, 1.97449664, 1.98724832, 2.        ]),\n",
       "                                        &#x27;min_samples_leaf&#x27;: [20, 21, 22, 23, 24,\n",
       "                                                             25, 26, 27, 28, 29,\n",
       "                                                             30, 31, 32, 33, 34,\n",
       "                                                             35, 36, 37, 38, 39,\n",
       "                                                             40, 41, 42, 43, 44,\n",
       "                                                             45, 46, 47, 48, 49, ...]},\n",
       "                   return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-4,\n",
       "                   param_distributions={'learning_rate': array([0.1       , 0.11275168, 0.12550336, 0.13825503, 0.15100671,\n",
       "       0.16375839, 0.17651007, 0.18926174, 0.20201342, 0.2147651 ,\n",
       "       0.22751678, 0.24026846, 0.25302013, 0.26577181, 0.27852349,\n",
       "       0.29127517, 0.30402685, 0.31677852, 0.3295302 , 0.34228188,\n",
       "       0.35503356, 0.36778523,...\n",
       "       1.75771812, 1.7704698 , 1.78322148, 1.79597315, 1.80872483,\n",
       "       1.82147651, 1.83422819, 1.84697987, 1.85973154, 1.87248322,\n",
       "       1.8852349 , 1.89798658, 1.91073826, 1.92348993, 1.93624161,\n",
       "       1.94899329, 1.96174497, 1.97449664, 1.98724832, 2.        ]),\n",
       "                                        'min_samples_leaf': [20, 21, 22, 23, 24,\n",
       "                                                             25, 26, 27, 28, 29,\n",
       "                                                             30, 31, 32, 33, 34,\n",
       "                                                             35, 36, 37, 38, 39,\n",
       "                                                             40, 41, 42, 43, 44,\n",
       "                                                             45, 46, 47, 48, 49, ...]},\n",
       "                   return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "# Create the parameter grid\n",
    "param_grid = {'learning_rate': np.linspace(0.1,2,150), 'min_samples_leaf': list(range(20,65))} \n",
    "\n",
    "# Create a random search object\n",
    "random_GBM_class = RandomizedSearchCV(\n",
    "    estimator = GradientBoostingClassifier(),\n",
    "    param_distributions= param_grid,\n",
    "    n_iter = 10,\n",
    "    scoring='accuracy', n_jobs=4, cv = 5, refit=True, return_train_score = True)\n",
    "\n",
    "# Fit to the training data\n",
    "random_GBM_class.fit(X_train , y_train)\n",
    "\n",
    "# Print the values used for both hyperparameters\n",
    "print(random_GBM_class.cv_results_['param_learning_rate'])\n",
    "print(random_GBM_class.cv_results_['param_min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_min_samples_leaf', 'param_learning_rate', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_GBM_class.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearchCV in Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice building a `RandomizedSearchCV` object using Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\88016\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\88016\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\88016\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\88016\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\88016\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\88016\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.77478528        nan 0.76666608 0.77230482        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\88016\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the train scores are non-finite: [0.7876658         nan 0.99989384 0.9849411         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 16 23 16 19]\n",
      "['sqrt' 'auto' 'sqrt' 'sqrt' 'auto']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create the parameter grid\n",
    "param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto' , 'sqrt']} \n",
    "\n",
    "# Create a random search object\n",
    "random_rf_class = RandomizedSearchCV(\n",
    "    estimator = RandomForestClassifier(n_estimators=80),\n",
    "    param_distributions = param_grid, n_iter = 5,\n",
    "    scoring='roc_auc', n_jobs=4, cv = 3, refit=True, return_train_score = True )\n",
    "\n",
    "# Fit to the training data\n",
    "random_rf_class.fit(X_train, y_train)\n",
    "\n",
    "# Print the values used for both hyperparameters\n",
    "print(random_rf_class.cv_results_['param_max_depth'])\n",
    "print(random_rf_class.cv_results_['param_max_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Random & Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you just studied some of the advantages and disadvantages of random search as compared to grid search.\n",
    "\n",
    "Which of the following is an advantage of random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is more computationally efficient than Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid and Random Search Side by Side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the search space of random and grid search together allows you to easily see the coverage that each technique has and therefore brings to life their specific advantages and disadvantages.\n",
    "\n",
    "In this exercise, you will sample hyperparameter combinations in a grid search way as well as a random search way, then plot these to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lims = [0.01, 3.0]\n",
    "y_lims = [5, 24]\n",
    "def visualize_search(grid_combinations_chosen, random_combinations_chosen):\n",
    "  grid_y, grid_x = [x[0] for x in grid_combinations_chosen], [x[1] for x in grid_combinations_chosen]\n",
    "  rand_y, rand_x = [x[0] for x in random_combinations_chosen], [x[1] for x in random_combinations_chosen]\n",
    "\n",
    "  # Plot all together\n",
    "  plt.scatter(grid_y + rand_y, grid_x + rand_x, c=['red']*300 + ['blue']*300)\n",
    "  plt.gca().set(xlabel='learn_rate', ylabel='min_samples_leaf', title='Grid and Random Search Hyperparameters')\n",
    "  plt.gca().set_xlim(x_lims)\n",
    "  plt.gca().set_ylim(y_lims)\n",
    "  plt.show()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['gini', 'auto', 3], ['gini', 'auto', 4], ['gini', 'auto', 5], ['gini', 'auto', 6], ['gini', 'auto', 7], ['gini', 'auto', 8], ['gini', 'auto', 9], ['gini', 'auto', 10], ['gini', 'auto', 11], ['gini', 'auto', 12], ['gini', 'auto', 13], ['gini', 'auto', 14], ['gini', 'auto', 15], ['gini', 'auto', 16], ['gini', 'auto', 17], ['gini', 'auto', 18], ['gini', 'auto', 19], ['gini', 'auto', 20], ['gini', 'auto', 21], ['gini', 'auto', 22], ['gini', 'auto', 23], ['gini', 'auto', 24], ['gini', 'auto', 25], ['gini', 'auto', 26], ['gini', 'auto', 27], ['gini', 'auto', 28], ['gini', 'auto', 29], ['gini', 'auto', 30], ['gini', 'auto', 31], ['gini', 'auto', 32], ['gini', 'auto', 33], ['gini', 'auto', 34], ['gini', 'auto', 35], ['gini', 'auto', 36], ['gini', 'auto', 37], ['gini', 'auto', 38], ['gini', 'auto', 39], ['gini', 'auto', 40], ['gini', 'auto', 41], ['gini', 'auto', 42], ['gini', 'auto', 43], ['gini', 'auto', 44], ['gini', 'auto', 45], ['gini', 'auto', 46], ['gini', 'auto', 47], ['gini', 'auto', 48], ['gini', 'auto', 49], ['gini', 'auto', 50], ['gini', 'auto', 51], ['gini', 'auto', 52], ['gini', 'auto', 53], ['gini', 'auto', 54], ['gini', 'auto', 55], ['gini', 'sqrt', 3], ['gini', 'sqrt', 4], ['gini', 'sqrt', 5], ['gini', 'sqrt', 6], ['gini', 'sqrt', 7], ['gini', 'sqrt', 8], ['gini', 'sqrt', 9], ['gini', 'sqrt', 10], ['gini', 'sqrt', 11], ['gini', 'sqrt', 12], ['gini', 'sqrt', 13], ['gini', 'sqrt', 14], ['gini', 'sqrt', 15], ['gini', 'sqrt', 16], ['gini', 'sqrt', 17], ['gini', 'sqrt', 18], ['gini', 'sqrt', 19], ['gini', 'sqrt', 20], ['gini', 'sqrt', 21], ['gini', 'sqrt', 22], ['gini', 'sqrt', 23], ['gini', 'sqrt', 24], ['gini', 'sqrt', 25], ['gini', 'sqrt', 26], ['gini', 'sqrt', 27], ['gini', 'sqrt', 28], ['gini', 'sqrt', 29], ['gini', 'sqrt', 30], ['gini', 'sqrt', 31], ['gini', 'sqrt', 32], ['gini', 'sqrt', 33], ['gini', 'sqrt', 34], ['gini', 'sqrt', 35], ['gini', 'sqrt', 36], ['gini', 'sqrt', 37], ['gini', 'sqrt', 38], ['gini', 'sqrt', 39], ['gini', 'sqrt', 40], ['gini', 'sqrt', 41], ['gini', 'sqrt', 42], ['gini', 'sqrt', 43], ['gini', 'sqrt', 44], ['gini', 'sqrt', 45], ['gini', 'sqrt', 46], ['gini', 'sqrt', 47], ['gini', 'sqrt', 48], ['gini', 'sqrt', 49], ['gini', 'sqrt', 50], ['gini', 'sqrt', 51], ['gini', 'sqrt', 52], ['gini', 'sqrt', 53], ['gini', 'sqrt', 54], ['gini', 'sqrt', 55], ['gini', 'log2', 3], ['gini', 'log2', 4], ['gini', 'log2', 5], ['gini', 'log2', 6], ['gini', 'log2', 7], ['gini', 'log2', 8], ['gini', 'log2', 9], ['gini', 'log2', 10], ['gini', 'log2', 11], ['gini', 'log2', 12], ['gini', 'log2', 13], ['gini', 'log2', 14], ['gini', 'log2', 15], ['gini', 'log2', 16], ['gini', 'log2', 17], ['gini', 'log2', 18], ['gini', 'log2', 19], ['gini', 'log2', 20], ['gini', 'log2', 21], ['gini', 'log2', 22], ['gini', 'log2', 23], ['gini', 'log2', 24], ['gini', 'log2', 25], ['gini', 'log2', 26], ['gini', 'log2', 27], ['gini', 'log2', 28], ['gini', 'log2', 29], ['gini', 'log2', 30], ['gini', 'log2', 31], ['gini', 'log2', 32], ['gini', 'log2', 33], ['gini', 'log2', 34], ['gini', 'log2', 35], ['gini', 'log2', 36], ['gini', 'log2', 37], ['gini', 'log2', 38], ['gini', 'log2', 39], ['gini', 'log2', 40], ['gini', 'log2', 41], ['gini', 'log2', 42], ['gini', 'log2', 43], ['gini', 'log2', 44], ['gini', 'log2', 45], ['gini', 'log2', 46], ['gini', 'log2', 47], ['gini', 'log2', 48], ['gini', 'log2', 49], ['gini', 'log2', 50], ['gini', 'log2', 51], ['gini', 'log2', 52], ['gini', 'log2', 53], ['gini', 'log2', 54], ['gini', 'log2', 55], ['gini', None, 3], ['gini', None, 4], ['gini', None, 5], ['gini', None, 6], ['gini', None, 7], ['gini', None, 8], ['gini', None, 9], ['gini', None, 10], ['gini', None, 11], ['gini', None, 12], ['gini', None, 13], ['gini', None, 14], ['gini', None, 15], ['gini', None, 16], ['gini', None, 17], ['gini', None, 18], ['gini', None, 19], ['gini', None, 20], ['gini', None, 21], ['gini', None, 22], ['gini', None, 23], ['gini', None, 24], ['gini', None, 25], ['gini', None, 26], ['gini', None, 27], ['gini', None, 28], ['gini', None, 29], ['gini', None, 30], ['gini', None, 31], ['gini', None, 32], ['gini', None, 33], ['gini', None, 34], ['gini', None, 35], ['gini', None, 36], ['gini', None, 37], ['gini', None, 38], ['gini', None, 39], ['gini', None, 40], ['gini', None, 41], ['gini', None, 42], ['gini', None, 43], ['gini', None, 44], ['gini', None, 45], ['gini', None, 46], ['gini', None, 47], ['gini', None, 48], ['gini', None, 49], ['gini', None, 50], ['gini', None, 51], ['gini', None, 52], ['gini', None, 53], ['gini', None, 54], ['gini', None, 55], ['entropy', 'auto', 3], ['entropy', 'auto', 4], ['entropy', 'auto', 5], ['entropy', 'auto', 6], ['entropy', 'auto', 7], ['entropy', 'auto', 8], ['entropy', 'auto', 9], ['entropy', 'auto', 10], ['entropy', 'auto', 11], ['entropy', 'auto', 12], ['entropy', 'auto', 13], ['entropy', 'auto', 14], ['entropy', 'auto', 15], ['entropy', 'auto', 16], ['entropy', 'auto', 17], ['entropy', 'auto', 18], ['entropy', 'auto', 19], ['entropy', 'auto', 20], ['entropy', 'auto', 21], ['entropy', 'auto', 22], ['entropy', 'auto', 23], ['entropy', 'auto', 24], ['entropy', 'auto', 25], ['entropy', 'auto', 26], ['entropy', 'auto', 27], ['entropy', 'auto', 28], ['entropy', 'auto', 29], ['entropy', 'auto', 30], ['entropy', 'auto', 31], ['entropy', 'auto', 32], ['entropy', 'auto', 33], ['entropy', 'auto', 34], ['entropy', 'auto', 35], ['entropy', 'auto', 36], ['entropy', 'auto', 37], ['entropy', 'auto', 38], ['entropy', 'auto', 39], ['entropy', 'auto', 40], ['entropy', 'auto', 41], ['entropy', 'auto', 42], ['entropy', 'auto', 43], ['entropy', 'auto', 44], ['entropy', 'auto', 45], ['entropy', 'auto', 46], ['entropy', 'auto', 47], ['entropy', 'auto', 48], ['entropy', 'auto', 49], ['entropy', 'auto', 50], ['entropy', 'auto', 51], ['entropy', 'auto', 52], ['entropy', 'auto', 53], ['entropy', 'auto', 54], ['entropy', 'auto', 55], ['entropy', 'sqrt', 3], ['entropy', 'sqrt', 4], ['entropy', 'sqrt', 5], ['entropy', 'sqrt', 6], ['entropy', 'sqrt', 7], ['entropy', 'sqrt', 8], ['entropy', 'sqrt', 9], ['entropy', 'sqrt', 10], ['entropy', 'sqrt', 11], ['entropy', 'sqrt', 12], ['entropy', 'sqrt', 13], ['entropy', 'sqrt', 14], ['entropy', 'sqrt', 15], ['entropy', 'sqrt', 16], ['entropy', 'sqrt', 17], ['entropy', 'sqrt', 18], ['entropy', 'sqrt', 19], ['entropy', 'sqrt', 20], ['entropy', 'sqrt', 21], ['entropy', 'sqrt', 22], ['entropy', 'sqrt', 23], ['entropy', 'sqrt', 24], ['entropy', 'sqrt', 25], ['entropy', 'sqrt', 26], ['entropy', 'sqrt', 27], ['entropy', 'sqrt', 28], ['entropy', 'sqrt', 29], ['entropy', 'sqrt', 30], ['entropy', 'sqrt', 31], ['entropy', 'sqrt', 32], ['entropy', 'sqrt', 33], ['entropy', 'sqrt', 34], ['entropy', 'sqrt', 35], ['entropy', 'sqrt', 36], ['entropy', 'sqrt', 37]]\n"
     ]
    }
   ],
   "source": [
    "# Sample grid coordinates\n",
    "grid_combinations_chosen = combinations_list[0:300]\n",
    "\n",
    "# Print result\n",
    "print(grid_combinations_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a list of sample indexes\n",
    "sample_indexes = list(range(0,len(combinations_list)))\n",
    "\n",
    "# Randomly sample 300 indexes\n",
    "random_indexes = np.random.choice(sample_indexes, 300, replace=False)\n",
    "\n",
    "# Use indexes to create random sample\n",
    "random_combinations_chosen = [combinations_list[index] for index in random_indexes]\n",
    "\n",
    "\n",
    "# # Call the function to produce the visualization\n",
    "# visualize_search(grid_combinations_chosen, random_combinations_chosen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
