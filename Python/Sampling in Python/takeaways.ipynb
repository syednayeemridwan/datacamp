{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- population = whole dataset\n",
    "- sample = subset of population\n",
    "    - sampling with replacement (for dependent event): `df[\"col\"].sample(5, replace = True)`\n",
    "    - sampling without replacement (for independent event): `df[\"col\"].sample(5, replace = False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Generate 10 uniform random values between 0 to 5\n",
    "from scipy.stats import uniform\n",
    "uniform.rvs(0, 5, size=10)\n",
    "# Generate binomial random values\n",
    "from scipy.stats import binom\n",
    "binom.rvs(1, 0.5, size=8) # 1 coin, flip 8 times, probability of success 50%\n",
    "binom.rvs(8, 0.5, size=1) # 8 coins, flip 1 time, probability of success 50%\n",
    "binom.rvs(3, 0.5, size=10) # 3 coins, flip 10 times, probability of success 50%\n",
    "\n",
    "# Generate 10 random normal values with mean 161 and std of 7\n",
    "from scipy.stats import norm\n",
    "norm.rvs(161, 7, size=10)\n",
    "\n",
    "# Generate 10 random poisson values with lambda of 8\n",
    "from scipy.stats import poisson\n",
    "poisson.rvs(8, size=10)\n",
    "\n",
    "# Generate 10 random values from a t-distribution with 5 degrees of freedom\n",
    "from scipy.stats import t\n",
    "t.rvs(df=5, size=10)\n",
    "\n",
    "# Generate 10 random values from a log-normal distribution with mean 1.5 and standard deviation 0.8\n",
    "from scipy.stats import lognorm\n",
    "lognorm.rvs(s=0.8, scale=1.5, size=10)\n",
    "\n",
    "#### Alternatives ###########\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "random_beta = np.random.beta(a=2, b=2, size=5000)\n",
    "random_normal = np.random.normal(loc=2, scale=1.5, size=2)\n",
    "random_uniform =  np.random.uniform(low=-3, high=3, size = 5000)\n",
    "\n",
    "# Visualize\n",
    "plt.hist(uniforms, bins = np.arange(-3,3.1,0.25))\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Systematic sampling : Sampling by taking every n-th element in a shuffled dataset\n",
    "- Simple random sampling : Sampling by taking purely random rows in a dataset\n",
    "- Stratified samping : sampling by keeping proportions of subgroups in account\n",
    "- Weighted sampling : sampling by adding weights to subgroups to adjust relative probability of a row being sampled\n",
    "- cluster sampling : First randomly pick subgroups of dataset, then randomly sample rows from those subgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Visualize sampling distribution\n",
    "df_sample = df.sample(n=10)\n",
    "df_sample[\"col\"].hist(bins=np.arange(59, 93, 2))\n",
    "plt.show()\n",
    "# Sampling with replacement (for dependent event)\n",
    "df[\"col\"].sample(5, replace = True)\n",
    "# Sampling without replacement (for independent event)\n",
    "df[\"col\"].sample(5, replace = False)\n",
    "\n",
    "# Simple random sampling\n",
    "simple_sample = df.sample(n=5, random_state=42)\n",
    "\n",
    "# Systematic sampling\n",
    "sample_size = 5\n",
    "pop_size = len(df)\n",
    "interval = pop_size // sample_size\n",
    "shuffled_df = df.sample(frac=1)\n",
    "shuffled_df = shuffled_df.reset_index(drop=True).reset_index()\n",
    "systematic_sample = shuffled_df.iloc[::interval]\n",
    "\n",
    "# Stratified sampling\n",
    "prop_stratified_sample = df.groupby(\"cat_col\").sample(frac=0.1, random_state=42)\n",
    "equal_stratified_sample = df.groupby(\"cat_col\").sample(n=15, random_state=42)\n",
    "\n",
    "# Weighted sampling\n",
    "condition = df['cat_col'] == \"Val\"\n",
    "df['weight'] = np.where(condition, 2, 1)\n",
    "weighted_sample = df.sample(frac=0.1, weights=\"weight\")\n",
    "\n",
    "# Cluster sampling\n",
    "category_list = list(df['cat_col'].unique())\n",
    "import random\n",
    "random_categories = random.sample(category_list, k=3)\n",
    "subset_rows = df['cat_col'].isin(random_categories)\n",
    "subset_df = df[subset_rows]\n",
    "subset_df['cat_col'] = subset_df['cat_col'].cat.remove_unused_categories()\n",
    "sample_cluster = subset_df.groupby(\"cat_col\").sample(n=5, random_state=42)\n",
    "\n",
    "# Visualize to make sure white noise so that sampling is random\n",
    "sample_df.plot(x=\"col1\", y=\"col2\", kind=\"scatter\")\n",
    "plt.show()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
