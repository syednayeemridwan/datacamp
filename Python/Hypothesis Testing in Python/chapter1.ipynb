{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uses of A/B testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the video, you saw how Electronic Arts used A/B testing on their website when launching SimCity 5. One version of the page showed an advertisement for a discount, and one version did not. Half the users saw one version of the page, and the other half saw the second version of the page.\n",
    "\n",
    "What is the main reason to use an A/B test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It provides a way to check outcomes of competing scenarios and decide which way to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the sample mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `late_shipments` dataset contains supply chain data on the delivery of medical supplies. Each row represents one delivery of a part. The late columns denotes whether or not the part was delivered late. A value of \"`Yes`\" means that the part was delivered late, and a value of \"`No`\" means the part was delivered on time.\n",
    "\n",
    "You'll begin your analysis by calculating a point estimate (or sample statistic), namely the proportion of late shipments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     0.939\n",
      "Yes    0.061\n",
      "Name: late, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "late_shipments = pd.read_feather(\"dataset/late_shipments.feather\")\n",
    "# Print the late_shipments dataset\n",
    "# print(late_shipments.head(1))\n",
    "\n",
    "# Calculate the proportion of late shipments\n",
    "late_prop_samp = late_shipments[\"late\"].value_counts(normalize = True)\n",
    "\n",
    "# Print the results\n",
    "print(late_prop_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'country', 'managed_by', 'fulfill_via', 'vendor_inco_term',\n",
       "       'shipment_mode', 'late_delivery', 'late', 'product_group',\n",
       "       'sub_classification', 'vendor', 'item_description',\n",
       "       'molecule_test_type', 'brand', 'dosage', 'dosage_form',\n",
       "       'unit_of_measure_per_pack', 'line_item_quantity', 'line_item_value',\n",
       "       'pack_price', 'unit_price', 'manufacturing_site',\n",
       "       'first_line_designation', 'weight_kilograms', 'freight_cost_usd',\n",
       "       'freight_cost_groups', 'line_item_insurance_usd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_shipments.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating a z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since variables have arbitrary ranges and units, we need to standardize them. For example, a hypothesis test that gave different answers if the variables were in Euros instead of US dollars would be of little value. Standardization avoids that.\n",
    "\n",
    "One standardized value of interest in a hypothesis test is called a z-score. To calculate it, you need three numbers: the sample statistic (point estimate), the hypothesized statistic, and the standard error of the statistic (estimated from the bootstrap distribution).\n",
    "\n",
    "The sample statistic is available as `late_prop_samp`.\n",
    "\n",
    "`late_shipments_boot_distn` is a bootstrap distribution of the proportion of late shipments, available as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_shipments_boot_distn = []\n",
    "for i in range(5000):\n",
    "    sample = late_shipments[\"late\"].sample(frac=1, replace=True)\n",
    "    yes_portion = sample.value_counts(normalize = True)[\"Yes\"]\n",
    "    late_shipments_boot_distn.append(yes_portion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13306250816653864\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Hypothesize that the proportion is 6%\n",
    "late_prop_hyp = 0.06\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.std(late_shipments_boot_distn, ddof = 1)\n",
    "\n",
    "# Find z-score of late_prop_samp\n",
    "z_score = (np.mean(late_prop_samp[\"Yes\"])- late_prop_hyp)/std_error\n",
    "\n",
    "# Print z_score\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criminal trials and hypothesis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the video, you saw how hypothesis testing follows a similar process to criminal trials.\n",
    "\n",
    "Which of the following correctly matches up a criminal trial with properties of a hypothesis test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just as the defendant is initially assumed not guilty, the null hypothesis is first assumed to be true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left tail, right tail, two tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis tests are used to determine whether the sample statistic lies in the tails of the null distribution. However, the way that the alternative hypothesis is phrased affects which tail(s) we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01.02.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine whether to choose the null hypothesis or the alternative hypothesis, you need to calculate a p-value from the z-score.\n",
    "\n",
    "You'll now return to the late shipments dataset and the proportion of late shipments.\n",
    "\n",
    "- The null hypothesis,  H0 , is that the proportion of late shipments is six percent.\n",
    "- The alternative hypothesis, HA, is that the proportion of late shipments is greater than six percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is a right-tailed hypothesis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "late_prop_samp_mean = 0.61\n",
    "hypothesised_mean = 0.6\n",
    "std_error = 0.007488520883926666\n",
    "\n",
    "from scipy.stats import norm\n",
    "# Calculate the z-score of late_prop_samp\n",
    "z_score = (np.mean(late_prop_samp) - late_prop_hyp) / std_error\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "                 \n",
    "# Print the p-value\n",
    "print(p_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decisions from p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value, denoted here as \n",
    ", is a measure of the amount of evidence to reject the null hypothesis or not. By comparing the p-value to the significance level, \n",
    ", you can make a decision about which hypothesis to support.\n",
    "\n",
    "Which of the following is the correct conclusion from the decision rule for a significance level  alpha?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  If the p-value is less than or equal to the significance level, you reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating a confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you give a single estimate of a sample statistic, you are bound to be wrong by some amount. For example, the hypothesized proportion of late shipments was 6%. Even if evidence suggests the null hypothesis that the proportion of late shipments is equal to this, for any new sample of shipments, the proportion is likely to be a little different due to sampling variability. Consequently, it's a good idea to state a confidence interval. That is, you say, \"we are 95% 'confident' that the proportion of late shipments is between A and B\" (for some value of A and B).\n",
    "\n",
    "Sampling in Python demonstrated two methods for calculating confidence intervals. Here, you'll use quantiles of the bootstrap distribution to calculate the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.047, 0.076)\n"
     ]
    }
   ],
   "source": [
    "# Calculate 95% confidence interval using quantile method\n",
    "lower = np.quantile(late_shipments_boot_distn, 0.025)\n",
    "upper = np.quantile(late_shipments_boot_distn, 0.975)\n",
    "\n",
    "# Print the confidence interval\n",
    "print((lower, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type I and type II errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hypothesis tests and for criminal trials, there are two states of truth and two possible outcomes. Two combinations are correct test outcomes, and there are two ways it can go wrong.\n",
    "\n",
    "The errors are known as false positives (or \"type I errors\"), and false negatives (or \"type II errors\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01.03.png\"  style=\"width: 400px, height: 300px;\"/></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
