{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hypothesis testing:\n",
    "    - Layman term : Method of testing if an assumption falls in feasible likelihood estimation or just a non-sense.\n",
    "    - Hypothesis : statement about an unknown population parameter (Your guess of the average value of a sample)\n",
    "    - Hypothesis test : test of two competing hypotheses. \n",
    "        - Null hypothesis : Your guess\n",
    "        - Alternative hypothesis : Challenging idea against your guess\n",
    "    - 3 tests: \n",
    "        - direction of test = direction of alternative hypothesis (or challenging idea)\n",
    "        - hypothesis for less or fewer = left tailed test\n",
    "        - hypothesis for greater or more = right tailed test\n",
    "        - hypothesis for different = two tailed test\n",
    "    - Testing Method : Compute sample mean and see the difference between guessed mean and sample mean. Measure if the difference is significant or not.\n",
    "    - Solution:\n",
    "        - z-test\n",
    "        - proportion z-test\n",
    "        - t-test\n",
    "        - ANOVA\n",
    "        - chi-square test of independence\n",
    "        - Chi-square goodness of fit\n",
    "        - Non-parametric Wilcoxon-signed rank test \n",
    "        - Non-parametric Wilcoxon-Mann-Whitney test\n",
    "        - Non-parametric Kruskal-Wallis test\n",
    "- A/B Testing : Hypothesis testing on 2 different scenarios (control vs treatment group)\n",
    "- p-value : \n",
    "    - probability of obtaining a result if the null hypothesis is true\n",
    "    - probability value from z-score or significance level\n",
    "    - Large p-value = p values not on tails = Large support for null hypothesis (p_value > alpha)\n",
    "    - Small p-value = p values on tails = No support for null hypothesis (p_value <= alpha)\n",
    "    - cut-off point = common significance level is 5%\n",
    "    - confidence interval = 1- alpha = 95%\n",
    "    - if the hypothesized population parameter is within the confidence interval, you should fail to reject the null hypothesis.\n",
    "- Null is False / Negative.\n",
    "- False Positive = Type 1 error\n",
    "- False Negative = Type 2 error\n",
    "    <center><img src=\"images/01.01.png\"  style=\"width: 400px, height: 300px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- z-test\n",
    "    - hypothesis testing on one-sample problem\n",
    "    - When population parameter is known\n",
    "    - Requires z-score (measure of how many standard deviations a data point is from the mean of a dataset)\n",
    "    - We test with the difference of between population and sample mean and its distribution\n",
    "    - Procedures:\n",
    "        - Bootstrap and get the mean of sample means\n",
    "        - measure standard daviation of bootstrap distribution\n",
    "        - find z-score = (sample mean - guessed or hypothesis mean) / standard daviation of bootstrap distribution\n",
    "        - convert z-score to p-value\n",
    "        - Compare p-value with significance level\n",
    "- Proportions z-test\n",
    "    - calculates if the difference in proportion of two categories across two variables have any significance\n",
    "    - Gives idea if two categorical columns have any association\n",
    "    - small p-value means the variables have association\n",
    "- t-test \n",
    "    -  hypothesis testing on two-sample problem and allows more uncertainty for two variables\n",
    "    - When a sample standard deviation is used in estimating a standard error instead of population parameters.\n",
    "    - Requires t-stat, with degree of freedom (no of values in a variable - 1)\n",
    "    - We test with the difference of sample means and its distribution\n",
    "    -  paired t-test : both variables are dependent on a third variable\n",
    "    - Procedures:\n",
    "        - get the mean of sample means of two different classes\n",
    "        - measure standard daviation of the two classes\n",
    "        - find t-stat = (sample1 mean - sample2 mean) / root over ((std of sample1^2/length of sample1) + (std of sample2^2/length of sample2))\n",
    "        - convert t-stat to p-value\n",
    "        - Compare p-value with significance level\n",
    "- ANOVA test\n",
    "    - hypothesis testing on more than 2 groups\n",
    "    - high chance of False Positive with more number of groups. use correction method to adjust p-values\n",
    "- Chi-square test of independence\n",
    "    - calculates if the difference in proportion of multiple categories across two variables have any significance\n",
    "    - Gives the idea if the two categorical variables are statistically independent of each other\n",
    "    - Statistical independence - proportion of successes in the response variable is the same across all categories of the explanatory variable\n",
    "    - p-value < significance level means the variables are not independent. Instead, they are associated\n",
    "    - No direction or tail or alternative argument since it is squared (Always right tailed test)\n",
    "- Chi-square goodness of fit\n",
    "    - Checks whether the hypothesised proportion are a good fit for the sample proportion\n",
    "    - Used to compare the proportion of a categorical variable's distribution across different dataset \n",
    "    - if p-value < significance level then we can say that the hypothesised proportion is not a good fit of the sample proportion\n",
    "- Non-parametric tests\n",
    "    - when sample size is very small (<30 for normal tests, < 10 for proportional tests, < 5 for chi-square tests)\n",
    "    - When the distribution is not normal\n",
    "- Non-parametric Wilcoxon-signed rank test :\n",
    "    - Works well with paired data\n",
    "    - Takes the elementwise difference between 2 columns \n",
    "    - Take the absolute value of the differences\n",
    "    - Rank the absolute values\n",
    "    - Split them into two parts. Add all ranks for values that were less than zero and add all ranks for values that were greater than zero\n",
    "    - take the minimum of the two sum\n",
    "- Non-parametric Wilcoxon-Mann-Whitney test:\n",
    "    - Works well with unpaired data of two categories\n",
    "    - requires to convert data from long to wide format\n",
    "- Non-parametric Kruskal-Wallis test:\n",
    "    - Works well for data with multiple categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pingouin\n",
    "# Z-test (One directional, left)\n",
    "pingouin.ztest(x=df['col1'], y=df['col2'], alternative='less')\n",
    "# Paired t-test (One directional, paired, left)\n",
    "pingouin.ttest(x=df['col1'], y=df['col2'], paired=True, alternative=\"less\")\n",
    "# ANOVA test (All possible combination of groups)\n",
    "pingouin.anova(data=df, dv=\"col\", between=\"cat_col\")\n",
    "pingouin.pairwise_tests(data=df, dv=\"col\", between=\"cat_col\", padjust=\"bonf\")\n",
    "\n",
    "# Proportion Z-test\n",
    "from statsmodels.stats import proportion\n",
    "z_score, p_val = proportion.proportions_ztest(count=[len(df[(df['cat_col1'] == 'A') & (df['cat_col2'] == 'X')]),\n",
    "                                            len(df[(df['cat_col1'] == 'B') & (df['cat_col2'] == 'X')])],\n",
    "                                      nobs=[len(df[df['cat_col1'] == 'A']),\n",
    "                                            len(df[df['cat_col1'] == 'B'])])\n",
    "# Chi-square test of independence\n",
    "expected, observed, stats = pingouin.chi2_independence(data=df, x=\"catcol1\", y=\"catcol2\")\n",
    "print(stats)\n",
    "\n",
    "\n",
    "# Perform chi-square goodness-of-fit test between two groupby dataframe results\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, _ = chi2_contingency([df1[\"col\"], df2[\"col\"]])\n",
    "\n",
    "# Non-parametric wilcoxon signed rank for paired t-test\n",
    "pingouin.wilcoxon(x=df['col1'], y=df['col2'], alternative=\"less\")\n",
    "\n",
    "# Non-parametric Wilcoxon-Mann-Whitney test for unpaired two categories t-test\n",
    "df_wide = df.pivot(columns='cat_col',values='num_col')\n",
    "pingouin.mwu(x=df_wide['cat1'], y=df_wide['cat2'], alternative='greater')\n",
    "\n",
    "# Non-parametric Kruskal-Wallis test for ANOVA / multiple categories\n",
    "pingouin.kruskal(data=df, dv='num_col', between='cat_col')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used to determine relationship between 2 categorical variables.\n",
    "- It tests for association between 2 variables and tells us how likely\n",
    "- the is association due to chance \n",
    "- The test assumes (null hypothesis) that the variables are independent.\n",
    "- The the model does not fit, then that proves that the variables are dependent.\n",
    "\n",
    "calculation steps: \n",
    "\n",
    "- use contigency table for observed values from a dataset.\n",
    "- on contigency table,  for each cell, (row total * column total)/grand total\n",
    "- this will create table with expected value \n",
    "- calculate chi square value: SUM((observed-expected)^2 / expected)\n",
    "- determine p-value for that chi square value\n",
    "- if p<0.05, then the variables are not independent (Reject null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sampled data must be randomly collected from the population\n",
    "- Size of dataset (Our generic assumption for parametric hypothesis tests)\n",
    "    - for normal tests : 30 sample data\n",
    "    - for proportion tests : 10 for each categorical data\n",
    "    - for chi-square tests : 5 for each categorical class\n",
    "    - sanity check : bootstrap distribution should be normally distributed\n",
    "- Otherwise do non-parametric hypothesis tests"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
