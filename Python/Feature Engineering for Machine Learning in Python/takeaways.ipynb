{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create new features\n",
    "- Transform existing features\n",
    "- Normalize features\n",
    "- Encoding : Convert categories into numeric data\n",
    "    - One-hot encoding : Explainable features, create N columns for N categories\n",
    "    - Dummy encoding : Necessary information without duplication, create N-1 columns for N categories\n",
    "- Merge low frequent categorical values (uncommon categories) into one single category (eg: `other`)\n",
    "- Binarise numeric values (eg: from `num_violations` to `violation_boolean`)\n",
    "- Deal with missing values:\n",
    "    - drop missing values that are beyond threshold (>30% of dataset)\n",
    "    - fill completely random missing values (with mean, median, mode, `Other`, sorted next present value)\n",
    "- Validate numeric columns\n",
    "    - remove characters from numeric data (eg: `$` or `,` sign for currency)\n",
    "    - make sure the column is in proper datatype (eg: `float`, `int` etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# One-hot encoding\n",
    "pd.get_dummies(df, columns=['cat'], prefix='C')\n",
    "# Dummy encoding\n",
    "pd.get_dummies(df, columns=['cat'], drop_first=True, prefix='C')\n",
    "\n",
    "# Merging low frequency categorical counts\n",
    "counts = df['cat'].value_counts()\n",
    "mask = df['cat'].isin(counts[counts < 5].index) \n",
    "df['cat'][mask] = 'Other'\n",
    "\n",
    "# Binarizing numeric variables\n",
    "df['Binary_col'] = 0 \n",
    "df.loc[df['Number_col'] > 0, 'Binary_col'] = 1\n",
    "import numpy as np\n",
    "df['Binned_Group'] = pd.cut( df['Number_col'], bins=[-np.inf, 0, 2, np.inf], labels=[1, 2, 3])\n",
    "\n",
    "# DEAL WITH MISSING VALUES.....\n",
    "\n",
    "# Validate numeric columns\n",
    "df['RawSalary'] = df['RawSalary'].str.replace(',', '').astype('float')\n",
    "coerced_vals = pd.to_numeric(df['RawSalary'], errors='coerce')\n",
    "print(df[coerced_vals.isna()].head()) # Sanity check which values still show errors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# create intervals for equal-sized 5 bins\n",
    "bins = np.linspace(df[\"price\"].min(), df[\"price\"].max(),5)\n",
    "custom_labels = [\"low\",\"medium\",\"high\"]\n",
    "df[\"price_bin\"] = pd.cut(df[\"price\"], bins, labels=custom_labels, include_lowest=True)\n",
    "\n",
    "# Alternative approach\n",
    "df['price_bin'] = pd.qcut(df['price'], q=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# See column names\n",
    "df.columns\n",
    "# Set column names\n",
    "df.columns = ['A', 'B', 'C']\n",
    "# Data type of columns\n",
    "df.dtypes\n",
    "# Select column of specific types only\n",
    "df_ints = df.select_dtypes(include=['int'])\n",
    "# Set type of a column\n",
    "df['num_col']=df['num_col'].astype(int)\n",
    "# See column description\n",
    "df.describe()\n",
    "# See column information\n",
    "df.info()\n",
    "# See frequencies in categorical column\n",
    "df['cat'].value_counts()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# One-hot-encoding on categorical variable\n",
    "df_onehot = pd.get_dummies(df, columns=['cat'], prefix='C')\n",
    "df_dummy = pd.get_dummies(df, columns=['cat'], drop_first=True, prefix='C')\n",
    "\n",
    "# Alternative approach-2\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "onehot_transformed = encoder.fit_transform(df['cat_col'].values.reshape(-1,1))\n",
    "# Convert into dataframe\n",
    "onehot_df = pd.DataFrame(onehot_transformed.toarray())\n",
    "# Add the encoded columns with original dataset, \n",
    "df = pd.concat([df, onehot_df], axis=1)\n",
    "# Drop the original column that you used for encoding \n",
    "df = df.drop('cat_col', axis=1)\n",
    "\n",
    "# Label encoding : Turning string labels into numeric values\n",
    "from sklearn import preprocessing\n",
    "encoder_lvl = preprocessing.LabelEncoder()\n",
    "# Specify the unique categories in the column to apply one-hot encoding\n",
    "encoder_lvl.fit([ 'LOW', 'NORMAL', 'HIGH'])\n",
    "# Apply one hot encoding on the third column of the dataset\n",
    "df[:,2] = encoder_lvl.transform(df[:,2]) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Show number of missing data\n",
    "df.isna().sum()\n",
    "\n",
    "# Visualize missing data information\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "msno.matrix(airquality)\n",
    "plt.show()\n",
    "\n",
    "# Drop missing data\n",
    "df_dropped = df.dropna(subset = ['col'])\n",
    "\n",
    "# Replace/impute missing data with single value\n",
    "col_mean = df['col'].mean()\n",
    "df_imputed = df.fillna({'col': col_mean})\n",
    "\n",
    "# Replace/impute missing data with series\n",
    "series_imp = df['col1'] * 5\n",
    "df_imputed = df.fillna({'col2':series_imp})\n",
    "\n",
    "# Missing values are not always \"NaN\". They can be blank, \"?\" or other symbols (rarely)\n",
    "# Check for values through manual validations first\n",
    "df[\"col\"].value_counts() # Look out for suspicious values\n",
    "# Determine number of missing values in a column\n",
    "df.isna().any()\n",
    "df['col'].isnull().sum()\n",
    "# Drop missing values\n",
    "df.dropna(axis = 0) # Drop entire row for missing value (default)\n",
    "df.dropna(axis = 1) # Drop entire column for missing value\n",
    "# Drop missing values for specific column\n",
    "df.dropna(subset = [\"col\"], axis = 0)\n",
    "# Replace missing values\n",
    "df[\"col\"].replace(np.nan, new_val)\n",
    "df.fillna(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
