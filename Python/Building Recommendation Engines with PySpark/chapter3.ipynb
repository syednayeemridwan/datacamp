{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "\t.master('local[*]') \\\n",
    "    .appName(\"Load and Query CSV with SQL\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.csv(\"dataset/ratings.csv\",sep=',', header=True, inferSchema=True, nullValue='NA') \n",
    "movies = spark.read.csv(\"dataset/movies.csv\",sep=',', header=True, inferSchema=True, nullValue='NA') \n",
    "tags = spark.read.csv(\"dataset/tags.csv\",sep=',', header=True, inferSchema=True, nullValue='NA') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the MovieLens Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Familiarize yourself with the ratings dataset provided here. Would you consider the data to be implicit or explicit ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userId', 'movieId', 'rating', 'timestamp']\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Look at the column names\n",
    "print(ratings.columns)\n",
    "\n",
    "# Look at the first few rows of data\n",
    "print(ratings.show(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, ALS works well with sparse datasets. Let's see how much of the ratings matrix is actually empty.\n",
    "\n",
    "Remember that sparsity is calculated by the number of cells in a matrix that contain a rating divided by the total number of values that matrix could hold given the number of users and items (movies). In other words, dividing the number of ratings present in the matrix by the product of users and movies in the matrix and subtracting that from 1 will give us the sparsity or the percentage of the ratings matrix that is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.30% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct userIds and distinct movieIds\n",
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The GroupBy and Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know a little more about the dataset, let's look at some general summary metrics of the ratings dataset and see how many ratings the movies have and how many ratings each users has provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   148|   48|\n",
      "|   463|   33|\n",
      "|   471|   28|\n",
      "+------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite packages\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# View the ratings dataset\n",
    "ratings.show(3)\n",
    "\n",
    "# Filter to show only userIds less than 100\n",
    "ratings.filter(col(\"userId\") < 100).show(3)\n",
    "\n",
    "# Group data by userId, count ratings\n",
    "ratings.groupBy(\"userId\").count().show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the groupBy() method a bit further.\n",
    "\n",
    "Once you've applied the .groupBy() method to a dataframe, you can subsequently run aggregate functions such as .sum(), .avg(), .min() and have the results grouped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n",
      "Avg num ratings per movie: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|10.369806663924312|\n",
      "+------------------+\n",
      "\n",
      "User with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|        20|\n",
      "+----------+\n",
      "\n",
      "Avg num ratings per user: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|165.30491803278687|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, avg\n",
    "# Min num ratings for movies\n",
    "print(\"Movie with the fewest ratings: \")\n",
    "ratings.groupBy(\"movieId\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per movie\n",
    "print(\"Avg num ratings per movie: \")\n",
    "ratings.groupBy(\"movieId\").count().select(avg(\"count\")).show()\n",
    "\n",
    "# Min num ratings for user\n",
    "print(\"User with the fewest ratings: \")\n",
    "ratings.groupBy(\"userId\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "ratings.groupBy(\"userId\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know from previous chapters, Spark's implementation of ALS requires that movieIds and userIds be provided as integer datatypes. Many datasets need to be prepared accordingly in order for them to function properly with Spark. A common issue is that Spark thinks numbers are strings, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .printSchema() to see the datatypes of the ratings dataset\n",
    "ratings.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tell Spark to convert the columns to the proper data types\n",
    "ratings = ratings.select(ratings.userId.cast(\"integer\"), ratings.movieId.cast(\"integer\"), ratings.rating.cast(\"double\"))\n",
    "\n",
    "# Call .printSchema() again to confirm the columns are now in the correct format\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test/train splits and build your ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already know how to build an ALS model, having done it in the previous chapter. We will do that again, but we'll take some additional steps to fully build out a cross-validated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False)\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tell Spark how to tune your ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to create a ParamGrid to tell Spark what hyperparameters we want it to tune, how to tune them, and then build out an evaluator so Spark can know how to measure the algorithm's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  1\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite items\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10]) \\\n",
    "            .addGrid(als.maxIter, [5] ) \\\n",
    "            .addGrid(als.regParam, [.05]  ) \\\n",
    "            .build()\n",
    "           \n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your cross validation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, our train/test splits, our model, and our hyperparameter values, let's tell Spark how to cross validate our model so it can find the best combination of hyperparameters and return it to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_f15967e4e861\n"
     ]
    }
   ],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model and Best Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our cross validator, cv, built out, we can tell Spark to take our data, fit the ALS algorithm to it, and try the different combinations of hyperparameter values from our param_grid so that it can identify what values provide the smallest RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALSModel: uid=ALS_10e5d64aca8b, rank=10\n"
     ]
    }
   ],
   "source": [
    "model = cv.fit(train)\n",
    "prediction = model.transform(test)\n",
    "best_model = model.bestModel\n",
    "# Print best_model\n",
    "print(model.bestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Best Model**\n",
      "  Rank: 10\n"
     ]
    }
   ],
   "source": [
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")\n",
    "\n",
    "# Print \"Rank\"\n",
    "print(\"  Rank:\", best_model.rank)\n",
    "\n",
    "# Print \"MaxIter\"\n",
    "# print(\"  MaxIter:\", best_model.getMaxIter()) \n",
    "\n",
    "# Print \"RegParam\"\n",
    "# print(\"  RegParam:\", best_model.getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions and calculate RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model that is trained on our data and tuned through cross validation, we can see how it performs on the test dataframe. To do this, we'll calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|      3|   4.0|  4.068782|\n",
      "|     1|     50|   5.0|  4.923078|\n",
      "|     1|    362|   5.0|  3.866249|\n",
      "+------+-------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# View the predictions \n",
    "prediction.show(3)\n",
    "\n",
    "# Calculate and print the RMSE of test_predictions\n",
    "RMSE = evaluator.evaluate(prediction)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was able to achieve an RMSE of 0.633. Click on the best interpretation of what this means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An RMSE of 0.633 means that on average the model predicts 0.633 above or below values of the original ratings matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do recommendations make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an understanding of how well our model performed, and have some confidence that it will provide recommendations that are relevant to users, let's actually look at recommendations made to a user and see if they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 60's Ratings:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    60|    527|   5.0|\n",
      "|    60|    858|   5.0|\n",
      "|    60|  58559|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "User 60s Recommendations:\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|    60|    318|   4.0|  4.246172|\n",
      "|    60|    362|   4.0| 4.0332055|\n",
      "|    60|   1562|   3.0| 2.4011354|\n",
      "+------+-------+------+----------+\n",
      "\n",
      "User 63's Ratings:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    63|    296|   5.0|\n",
      "|    63|      1|   5.0|\n",
      "|    63|    318|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "User 63's Recommendations:\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|    63|     34|   3.0| 3.7479832|\n",
      "|    63|    344|   5.0|  2.688593|\n",
      "|    63|    356|   3.5| 3.9641566|\n",
      "+------+-------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at user 60's ratings\n",
    "print(\"User 60's Ratings:\")\n",
    "ratings.filter(col(\"userId\") == 60).sort(\"rating\", ascending = False).show(3)\n",
    "\n",
    "# Look at the movies recommended to user 60\n",
    "print(\"User 60s Recommendations:\")\n",
    "prediction.filter(col(\"userId\") == 60).show(3)\n",
    "\n",
    "# Look at user 63's ratings\n",
    "print(\"User 63's Ratings:\")\n",
    "ratings.filter(col(\"userId\") == 63).sort(\"rating\", ascending = False).show(3)\n",
    "\n",
    "# Look at the movies recommended to user 63\n",
    "print(\"User 63's Recommendations:\")\n",
    "prediction.filter(col(\"userId\") == 63).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{8477, 6.528834}...|\n",
      "|     2|[{1241, 5.9868026...|\n",
      "|     3|[{6835, 5.1822457...|\n",
      "+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecs = best_model.recommendForAllUsers(5)\n",
    "userRecs.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------------+-------+---------+\n",
      "|userId|     recommendations|    movieId_rating|movieId|   rating|\n",
      "+------+--------------------+------------------+-------+---------+\n",
      "|     1|[{8477, 6.528834}...|  {8477, 6.528834}|   8477| 6.528834|\n",
      "|     1|[{8477, 6.528834}...|{92535, 5.9355555}|  92535|5.9355555|\n",
      "|     1|[{8477, 6.528834}...|{86377, 5.8888526}|  86377|5.8888526|\n",
      "|     1|[{8477, 6.528834}...|{27156, 5.8701963}|  27156|5.8701963|\n",
      "|     1|[{8477, 6.528834}...|   {28, 5.8553843}|     28|5.8553843|\n",
      "|     2|[{1241, 5.9868026...| {1241, 5.9868026}|   1241|5.9868026|\n",
      "|     2|[{1241, 5.9868026...|{72171, 5.8943777}|  72171|5.8943777|\n",
      "|     2|[{1241, 5.9868026...|{157775, 5.516651}| 157775| 5.516651|\n",
      "|     2|[{1241, 5.9868026...|{156025, 5.516651}| 156025| 5.516651|\n",
      "|     2|[{1241, 5.9868026...|{150554, 5.516651}| 150554| 5.516651|\n",
      "|     3|[{6835, 5.1822457...| {6835, 5.1822457}|   6835|5.1822457|\n",
      "|     3|[{6835, 5.1822457...| {5746, 5.1822457}|   5746|5.1822457|\n",
      "|     3|[{6835, 5.1822457...|  {5181, 5.098275}|   5181| 5.098275|\n",
      "|     3|[{6835, 5.1822457...| {7991, 5.0822062}|   7991|5.0822062|\n",
      "|     3|[{6835, 5.1822457...|  {5919, 5.075665}|   5919| 5.075665|\n",
      "|     4|[{25850, 6.61263}...|  {25850, 6.61263}|  25850|  6.61263|\n",
      "|     4|[{25850, 6.61263}...| {7982, 6.4221554}|   7982|6.4221554|\n",
      "|     4|[{25850, 6.61263}...|{49932, 6.1350718}|  49932|6.1350718|\n",
      "|     4|[{25850, 6.61263}...| {3265, 6.0865326}|   3265|6.0865326|\n",
      "|     4|[{25850, 6.61263}...|  {6643, 6.069419}|   6643| 6.069419|\n",
      "+------+--------------------+------------------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('userId', 'int'),\n",
       " ('recommendations', 'array<struct<movieId:int,rating:float>>'),\n",
       " ('movieId_rating', 'struct<movieId:int,rating:float>'),\n",
       " ('movieId', 'int'),\n",
       " ('rating', 'float')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "# Explode recommendations column to separate itemId and prediction\n",
    "recommendations_df = userRecs.withColumn(\"movieId_rating\", explode(\"recommendations\")) \n",
    "recommendations_df = recommendations_df.withColumn(\"movieId\", col(\"movieId_rating\").getField(\"movieId\"))\\\n",
    "                .withColumn(\"rating\", col(\"movieId_rating\").getField(\"rating\")) # Separate item\n",
    "recommendations_df.show()\n",
    "recommendations_df.dtypes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
