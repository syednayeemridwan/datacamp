{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some movies have multiple genres (a movie can be of both comedy and romance genre)\n",
    "- However, individual people might experience only a single genre from these movies\n",
    "- How to tell which person thinks the movie falls morely on which genre?\n",
    "- Latent feature (also known as Rank) tells that. \n",
    "- ALS algorithm decomposes original table into 2 matrices : User-Movie = User-LatentFeature X LatentFeature-Movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01.01.png\"  style=\"width: 400px, height: 300px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How ALS figures out recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.01.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.02.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.03.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original Rating table is decomposed into User and Product tables with random numbers\n",
    "- The random values in User table and Product table is adjusted through a number of iterations by reducing r-squared values\n",
    "- The minimized factorized table closely resembles the original Rating table.\n",
    "- While the original table has many missing values, the factorized table now contains the predicted values which can be considered as recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# View left factor matrix\n",
    "print(U)\n",
    "# View right factor matrix\n",
    "print(P)\n",
    "# Multiply factor matrices\n",
    "UP = np.matmul(U,P)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "print(pd.DataFrame(UP, columns = P.columns, index = U.index))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.04.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/02.05.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements to apply pyspark ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataframe must be in long format (NOT wide format)\n",
    "- 2 separate tables (User table and Product table) should have unique id in integer data-type\n",
    "- the individual tables should be coalesced into one partition to make the id consistent\n",
    "- when using `monotonically_increasing_id`, make sure to cache/persist the dataframes or the values might change\n",
    "- the tables should be merged together to create the Rating table. \n",
    "- ALS is applied on the Rating table\n",
    "- use `nonnegative = True` to ensure positive values\n",
    "- use `rank` to specify number of latent features you want to use\n",
    "- use `implicitPrefs= True` along with `alpha` only when you do not have explicit `rating` column\n",
    "- use `maxIter` to adjust weights for n number of iterations for reduced r-squared\n",
    "- use `coldStartStrategy = \"drop\"` to avoid testing on unknown user-product pair (if training data has no information on particular userid and productid )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.06.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALS Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data (User ID, Item ID, Rating, Additional Column1, Additional Column2)\n",
    "data = [\n",
    "    (1, 1, 5, \"A\", \"X\"),\n",
    "# .............................\n",
    "    (3, 2, 2, \"F\", \"U\")\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"userId\", \"itemId\", \"rating\", \"user_cat\", \"item_cat\"])\n",
    "# If user ID and/or Item ID do not exist and rather only categories exist, make unique identifier in separate dataframes for each distinct category and then join\n",
    "users = df.select(\"user_cat\").distinct().coalesce(1) # coalesce to put them in a single partition for consistent increase of id\n",
    "users = users.withColumn(\"userId\", monotonically_increasing_id()).persist() # caching to make sure the values do not change\n",
    "items = df.select(\"item_cat\").distinct().coalesce(1) # coalesce to put them in a single partition for consistent increase of id\n",
    "items = items.withColumn(\"itemId\", monotonically_increasing_id()).persist() # caching to make sure the values do not change\n",
    "df = = df.join(users, \"user_cat\", \"left\").join(items, \"item_cat\", \"left\")\n",
    "\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2]) # Split data into training and test sets\n",
    "\n",
    "# Train with ALS model\n",
    "als = ALS(rank=10, maxIter=10, regParam=0.01, userCol=\"userId\", itemCol=\"itemId\", ratingCol=\"rating\")\n",
    "model = als.fit(training_data)\n",
    "predictions = model.transform(test_data) # Make predictions on test data\n",
    "# Evaluate predictions using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
