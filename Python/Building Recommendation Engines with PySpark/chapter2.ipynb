{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand matrix multiplication more directly, let's do some matrix operations manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: \n",
      "     0  1\n",
      "One  2  2\n",
      "Two  3  3\n",
      "Matrix B: \n",
      "     0  1\n",
      "One  1  2\n",
      "Two  4  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "a  = np.array([[2, 2], [3, 3]])\n",
    "b = np.array([[1, 2], [4, 4]])\n",
    "a = pd.DataFrame(a, index=['One', 'Two'], columns=[0, 1])\n",
    "b = pd.DataFrame(b, index=['One', 'Two'], columns=[0, 1])\n",
    "\n",
    "# Use the .head() method to view the contents of matrices a and b\n",
    "print(\"Matrix A: \")\n",
    "print (a.head())\n",
    "\n",
    "print(\"Matrix B: \")\n",
    "print (b.head())\n",
    "\n",
    "# Complete the matrix with the product of matrices a and b\n",
    "product = np.array([[10,12], [15,18]])\n",
    "\n",
    "# Run this validation to see how your estimate performs\n",
    "product == np.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put your matrix multiplication skills to the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of a\n",
    "print(a.shape)\n",
    "\n",
    "# Print the dimensions of b\n",
    "print(b.shape)\n",
    "\n",
    "# Can C and D be multiplied together?\n",
    "a_times_b = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix G is provided here as a Pandas dataframe. View it to understand what it looks like. Look at the possible factor matrices H, I, and J (also Pandas dataframes), and determine which two matrices will produce the matrix G when multiplied together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take a look at Matrix G using the following print function\n",
    "# print(\"Matrix G:\")\n",
    "# print(G)\n",
    "\n",
    "# # Take a look at the matrices H, I, and J and determine which pair of those matrices will produce G when multiplied together. \n",
    "# print(\"Matrix H:\")\n",
    "# print(H)\n",
    "# print(\"Matrix I:\")\n",
    "# print(I)\n",
    "# print(\"Matrix J:\")\n",
    "# print(J)\n",
    "\n",
    "# # Multiply the two matrices that are factors of the matrix G\n",
    "# prod = np.matmul(H, J)\n",
    "# print(G == prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible for one matrix to have two equally close factorizations where one has all positive values and the other has some negative values.\n",
    "\n",
    "The matrix M has been factored twice using two different factorizations. Take a look at each pair of factor matrices L and U, and W and H to see the differences. Then use their products to see that they produce essentially the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # View the L, U, W, and H matrices.\n",
    "# print(\"Matrices L and U:\") \n",
    "# print(L)\n",
    "# print(U)\n",
    "\n",
    "# print(\"Matrices W and H:\")\n",
    "# print(W)\n",
    "# print(H)\n",
    "\n",
    "# # Calculate RMSE between LU and M\n",
    "# print(\"RMSE of LU: \", getRMSE(LU, M))\n",
    "\n",
    "# # Calculate RMSE between WH and M\n",
    "# print(\"RMSE of WH: \", getRMSE(WH, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your knowledge of matrix multiplication to determine which movie will have the highest recommendation for User_3. The ratings matrix has been factorized into U and P with ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # View left factor matrix\n",
    "# print(U)\n",
    "# # View right factor matrix\n",
    "# print(P)\n",
    "# # Multiply factor matrices\n",
    "# UP = np.matmul(U,P)\n",
    "\n",
    "# # Convert to pandas DataFrame\n",
    "# print(pd.DataFrame(UP, columns = P.columns, index = U.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE as ALS alternates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, ALS will alternate between the two factor matrices, adjusting their values each time to iteratively come closer and closer to approximating the original ratings matrix. This exercise is intended to illustrate this to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use getRMSE(preds, actuals) to calculate the RMSE of matrices T and F1.\n",
    "# getRMSE(F1, T)\n",
    "\n",
    "# # Create list of F2, F3, F4, F5, and F6\n",
    "# Fs = [F2, F3, F4, F5, F6]\n",
    "\n",
    "# # Calculate RMSE for F2, F3, F4, F5, and F6.\n",
    "# getRMSEs(Fs, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct format and distinct users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the R dataframe. Notice that it is in conventional or \"wide\" format with a different movie in each column. Also notice that the User's and movie names are not in integer format. Follow the steps to properly prepare this data for ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import monotonically_increasing_id and show R\n",
    "# from pyspark.sql.functions import monotonically_increasing_id\n",
    "# R.show()\n",
    "\n",
    "# # Use the to_long() function to convert the dataframe to the \"long\" format.\n",
    "# ratings = to_long(R)\n",
    "# ratings.show()\n",
    "\n",
    "# # Get unique users and repartition to 1 partition\n",
    "# users = ratings.select(\"User\").distinct().coalesce(1)\n",
    "\n",
    "# # Create a new column of unique integers called \"userId\" in the users dataframe.\n",
    "# users = users.withColumn(\"userId\", monotonically_increasing_id()).persist()\n",
    "# users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning integer id's to movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same thing to the movies. Then let's join the new user IDs and movie IDs into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the distinct movie id's\n",
    "# movies = ratings.select(\"Movie\").distinct() \n",
    "\n",
    "# # Repartition the data to have only one partition.\n",
    "# movies = movies.coalesce(1) \n",
    "\n",
    "# # Create a new column of movieId integers. \n",
    "# movies = movies.withColumn(\"movieId\", monotonically_increasing_id()) \n",
    "\n",
    "# # Join the ratings, users and movies dataframes\n",
    "# movie_ratings = ratings.join(users, \"User\", \"left\").join(movies, \"Movie\", \"left\")\n",
    "# movie_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build out an ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify your first ALS model. Complete the code below to build your first ALS model.\n",
    "\n",
    "Recall that you can use the .columns method on the ratings data frame to see what the names of the columns are that contain user, movie, and ratings data. Spark needs to know the names of these columns in order to perform ALS correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the ratings dataframe into training and test data\n",
    "# (training_data, test_data) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# # Set the ALS hyperparameters\n",
    "# from pyspark.ml.recommendation import ALS\n",
    "# als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", rank =10, maxIter =15, regParam =0.1,\n",
    "#           coldStartStrategy=\"drop\", nonnegative =True, implicitPrefs = False)\n",
    "\n",
    "# # Fit the mdoel to the training_data\n",
    "# model = als.fit(training_data)\n",
    "\n",
    "# # Generate predictions on the test_data\n",
    "# test_predictions = model.transform(test_data)\n",
    "# test_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RMSE evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to fit a model to training data and generate test predictions, you need a way to evaluate how well your model performs. For this we'll build an evaluator. Evaluators in Spark can be built out in various ways. For our purposes, we want a regressionEvaluator that calculates the RMSE. After we build our regressionEvaluator, we can fit the model to our data and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import RegressionEvaluator\n",
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# # Complete the evaluator code\n",
    "# evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"ratings\", predictionCol=\"prediction\")\n",
    "\n",
    "# # Extract the 3 parameters\n",
    "# print(evaluator.getMetricName())\n",
    "# print(evaluator.getLabelCol())\n",
    "# print(evaluator.getPredictionCol())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to build a model and generate predictions, and have an evaluator to tell us how well it predicts ratings, we can calculate the RMSE to see how well an ALS model performed. We'll use the evaluator that we built in the previous exercise to calculate and print the rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the \"test_predictions\" dataframe\n",
    "# RMSE = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# # Print the RMSE\n",
    "# print (RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
