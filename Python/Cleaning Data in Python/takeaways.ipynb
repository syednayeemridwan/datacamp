{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See datatype of columns : `df.dtypes`\n",
    "- See dataframe information : `df.info()`\n",
    "- See column information : `df.describe()`\n",
    "- Remove character : `df['col'].str.strip('$')`\n",
    "- Drop values : `df.drop(df[df['col'] > 5].index, inplace = True)`\n",
    "- Set values :\n",
    "    1. `df.loc[df['col'] > 5, 'col2'] = 5`\n",
    "    2. `df.at[df['col'] > 5,'col2']= 5`\n",
    "- Convert type : \n",
    "    - Other data type : `df['col'].astype('int')`\n",
    "    - Catergorical : `df[\"col\"].astype('category')`\n",
    "    - Date : `df['date_column'] = pd.to_datetime(df['datetime_column']).dt.date`\n",
    "- Test : `assert df['col'].dtype == 'int'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips to filter unclean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if integer values are meant to be categorical values\n",
    "- check for unwanted characters\n",
    "- Check if numerical values are converted into strings\n",
    "- Check for out of range values\n",
    "- Check for missing values\n",
    "- Check if dates are in proper format\n",
    "- Check for range of dates (if there are impossible values)\n",
    "- Check for duplicates (both complete and partial)\n",
    "- Checking constrains\n",
    "- cross-field validation : sanity / validity check using multiple fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Duplications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Drop complete duplicates\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "# Column names to check for partial duplicates\n",
    "column_names = ['A','B','C']\n",
    "duplicates = df.duplicated(subset = column_names, keep = False)\n",
    "# See partial duplicate values\n",
    "df[duplicates]\n",
    "\n",
    "# Combine result for partial duplicates\n",
    "summaries = {'D': 'max', 'E': 'mean'}\n",
    "df = df.groupby(by = column_names).agg(summaries).reset_index()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter out inconsistent categorical data by comparing them with known categories using anti-join\n",
    "- uppercase : `df['col'].str.upper()`\n",
    "- lowercase : `df['col'].str.lower()`\n",
    "- Remove character : `df['col'].str.strip('$')`\n",
    "- Replace character : \n",
    "    1. `df['col'] = df['col'].apply(lambda x: x.replace('_', '+'))`\n",
    "    2. `df['col'] = df['col'].str.replace('_', '+')`\n",
    "    3. `df['col'] = df['col'].str.replace(r'\\D+', '')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Type constrains : data type\n",
    "- Range constrains : Range of data\n",
    "- Uniqueness constrains : Unique value of row\n",
    "- Membership constain : Known member in a group (eg: month from 1 to 12, week from 1 to 7 etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "# Way 1 : Equal cut\n",
    "group_names = ['0-200K', '200K-500K', '500K+']\n",
    "df['cat'] = pd.qcut(df['range_col'], q = 3, labels = group_names)\n",
    "\n",
    "# Way 2 : More precise\n",
    "ranges = [0,200000,500000,np.inf]\n",
    "group_names = ['0-200K', '200K-500K', '500K+']\n",
    "# Create income group column\n",
    "df['cat'] = pd.cut(df['range_col'], bins=ranges, labels=group_names)\n",
    "\n",
    "# Way 3 : Mapping\n",
    "mapping = {'MALE':'M', 'Male':'M', 'FEMALE':'F', 'Female':'F'}\n",
    "df['cat'] = df['string_col'].replace(mapping)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "assert df['col'].dtype == 'int'\n",
    "assert phone['Phone number'].str.contains(\"+|-\").any() == False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Missing Completely at Random: \n",
    "\t- No systematic relationship between a column's missing values and \n",
    "    other or own values. \n",
    "    - eg : errors when inputting data\n",
    "2. Missing at Random: \n",
    "\t- There is a systematic relationship between a \n",
    "\tcolumn's missing values and other observed values.\n",
    "    - eg : missing ozone data for high temperature\n",
    "3. Missing not at Random: \n",
    "\t- There is a systematic relationship between a \n",
    "\tcolumn's missing values and unobserved values.\n",
    "    - eg : missing temperature values for high temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Show number of missing data\n",
    "df.isna().sum()\n",
    "\n",
    "# Visualize missing data information\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "msno.matrix(airquality)\n",
    "plt.show()\n",
    "\n",
    "# Drop missing data\n",
    "df_dropped = df.dropna(subset = ['col'])\n",
    "\n",
    "# Replace/impute missing data with single value\n",
    "col_mean = df['col'].mean()\n",
    "df_imputed = df.fillna({'col': col_mean})\n",
    "\n",
    "# Replace/impute missing data with series\n",
    "series_imp = df['col1'] * 5\n",
    "df_imputed = df.fillna({'col2':series_imp})\n",
    "\n",
    "# Missing values are not always \"NaN\". They can be blank, \"?\" or other symbols (rarely)\n",
    "# Check for values through manual validations first\n",
    "df[\"col\"].value_counts() # Look out for suspicious values\n",
    "# Determine number of missing values in a column\n",
    "df.isna().any()\n",
    "df['col'].isnull().sum()\n",
    "# Drop missing values\n",
    "df.dropna(axis = 0) # Drop entire row for missing value (default)\n",
    "df.dropna(axis = 1) # Drop entire column for missing value\n",
    "# Drop missing values for specific column\n",
    "df.dropna(subset = [\"col\"], axis = 0)\n",
    "# Replace missing values\n",
    "df[\"col\"].replace(np.nan, new_val)\n",
    "df.fillna(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Way 1\n",
    "df[\"date_col\"] = pd.to_datetime(df[\"date_col\"], \n",
    "                                infer_datetime_format=True,\n",
    "                                errors='coerce')\n",
    "# Way 2\n",
    "df[\"date_col\"] = df[\"date_col\"].dt.strftime(\"%d-%m-%Y\")\n",
    "# Extract month information\n",
    "dataframe[\"date_col\"].dt.month\n",
    "# Extract year information\n",
    "dataframe[\"date_col\"].dt.year\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
