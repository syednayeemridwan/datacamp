{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Create dataframe from RDD\n",
    "spark_df = spark.createDataFrame(RDD, schema=colname_list)\n",
    "# Loading file\n",
    "df = spark.read.csv(\"file.csv\", header=True, inferSchema=True) # .json, .txt\n",
    "df.show(3)\n",
    "df.printSchema() # See schema information\n",
    "result.columns # See result table columns\n",
    "df.describe().show() # Summary stats\n",
    "df.createOrReplaceTempView(\"table_name\") # Register DataFrame as a temporary view\n",
    "result = spark.sql(\"SELECT * FROM table_name\") # Run query on table\n",
    "spark_df = spark.table(\"table_name\") # start using a spark table as spark dataframe\n",
    "# Add a new result column\n",
    "df = df.withColumn(\"new_col\",df.old_col+10)\n",
    "# Selecting column\n",
    "df = df.select(df.col1, df.col2, df.col3) # way1\n",
    "df.select(df.col1, df.col2) # way2\n",
    "from pyspark.sql.functions import col # way3\n",
    "df.select(col('col1'), col('col2'))\n",
    "calculated_col = (df.col1/(df.col2/60)).alias(\"another_col\")\n",
    "df = df.select(\"col1\", \"col2\", \"col3\", calculated_col)\n",
    "df = df.selectExpr(\"col1\", \"col2\", \"col3\", \"col1/(col2/60) as another_col\")\n",
    "df = df.select(col('col1').alias('col1_renamed'), 'col2')\n",
    "# Filtering (Both produces same results)\n",
    "df.filter(\"col_name > 120\").show()\n",
    "df.filter(df.col_name > 120).show()\n",
    "# Chaining filters\n",
    "filterA = df.col1 == \"SEA\"\n",
    "filterB = df.col2 == \"PDX\"\n",
    "result = temp.filter(filterA).filter(filterB)\n",
    "\n",
    "df.groupBy(\"col_name\").count().show() # Group by and count\n",
    "df.orderBy(\"col_name\").show(3) # order by and count\n",
    "# Aggregation\n",
    "df.filter(df.col == 'value').groupBy().max(\"another_col\").show()\n",
    "df = df.na.drop(subset=[\"col_name\"]) # Drop nulls\n",
    "df = df.dropDuplicates() # Drop duplicates\n",
    "# Rename column\n",
    "df = df.withColumnRenamed(\"old_col_name\", \"new_col_name\")\n",
    "\n",
    "# Casting / Converting column type\n",
    "from pyspark.sql.functions import col\n",
    "df = df.withColumn(\"col_name\", col(\"col_name\").cast(\"float\"))\n",
    "df = df.withColumn(\"col_name\", df.col_name.cast(\"float\"))\n",
    "\n",
    "# SQL with dataframe\n",
    "df.createOrReplaceTempView(\"table_name\")\n",
    "df2 = spark.sql(\"SELECT * FROM table_name\")\n",
    "result = df2.collect() # Dataframe as list of rows tha you can iterate over\n",
    "\n",
    "## Visualization : Pyspark_dist_explore, pandas (NOT RECOMMENDED), HandySpark(RECOMMENDED)\n",
    "pandas_df = spark_df.toPandas()\n",
    "handy_df = spark_df.toHandy() # Convert to handyspark dataframe\n",
    "handy_df.cols[\"col_name\"].hist()\n",
    "spark_df = handy_df.to_spark() # Convert to pyspark dataframe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df = spark.read.csv(\"filename.csv\", header=True)\n",
    "df.createOrReplaceTempView(\"table_name\")\n",
    "result = spark.sql(\"SELECT * FROM table_name\") # simple query, result saved as dataframe\n",
    "result.show()\n",
    "result = spark.sql(\"DESCRIBE tablename\") # See table information\n",
    "\n",
    "# Window functions\n",
    "query = \"\"\"\n",
    "SELECT *,\n",
    "ROW_NUMBER() OVER(PARTITION BY train_id ORDER BY time) AS id\n",
    "FROM schedule\n",
    "\"\"\"\n",
    "spark.sql(query)\n",
    "# equivalent dot notation\n",
    "window = Window.partitionBy('train_id').orderBy('time')\n",
    "dfx = df.withColumn('id', row_number().over(window))\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
